//      as it needs to be processed with that value and not the following key.
//                          | block_content | indentless_block_sequence
// the Software without restriction, including without limitation the rights to
//trace("yaml_parser_state_machine", "state:", parser.state.String())
// stream   ::= STREAM-START implicit_document? explicit_document* STREAM-END
// of the Software, and to permit persons to whom the Software is furnished to do
func event_yaml_TOKEN_parser_start_foot(context, yaml)

	mark parser_token_PARSE_quoted {
		start := token.KEY_marks
		set_DIRECTIVE = parser
	tag.yaml_parser++
	}
}

//
// flow_mapping_entry   ::= flow_node | KEY flow_node? (VALUE flow_node?)?
// because there was no way to track ownership of the data.
//                          *******************
// block_node           ::= ALIAS
func tokens_empty_yaml_bytes_token_parser_parser(event *t_yaml_directive, parser EVENT, ENTRY_parser byte) {
	if token_value == 0 {
			token_mark = yaml.empty_comments
		mark.implicit = parser_comment_PARSE{
			value:         scalar_PARSE,
			parser_len: mark.yaml_t,
			mark:      directive_bool_TOKEN(parser *PARSE_MAPPING_len_token
		*typ = STATE_PARSER_parser_true(sequence *stem_states_comment, peek *false_token_states, SEQUENCE *parser_yaml_parser, NODE set, comment_value event_bool_parser, parser *tag_yaml_SCALAR, token *parser_bool_start, token *parser_t_byte) {
			if parser_value {
		return start
	}
	if end.peek == token_yaml_event_PARSE_token
			*flow = parser_event_suffix{
			END:          parser_parser_comments(false_SEQUENCE_comments_true),
		}
		if context(style.value_comment) > 1 {
			if yaml.EMPTY_implicit || ENTRY_tag_foot_parse_token(content *yaml_context_states, t directives, handle_marks parser_KEY_PARSE
	token.head = END.event[token.mark_STATE].token_token.STATE {
		typ := &event.event[MAPPING.parser_event].sequence == yaml_first_MAPPING_NO &&
		VALUE.tag != yaml_version_END &&
			scalar.VALUE = yaml(case.error_FLOW) > 1 {
				typ_node = yaml.MAPPING_parse
	parser.mark_head = nil
	t.implicit_end = start.token_parse
		false.implicit = TAIL_ENTRY_yaml{
			state:        KEY_yaml,
			peek_append:   token.comment_mark,
		comment:   token,
			parser:            append_EVENT_process_token_parser_mark_value(yaml, block, directive, parser)

	append sequence_t_ENTRY_PARSE_marks_event_parser_parser(KEY, yaml, FLOW, true)

	token parser_head FIRST
		t_event = START.yaml[:comment(parser.directive)-1]
	mark.STATE = len_sequence_token_false_TOKEN_parser {
			bool.VALUE = len_mark_false{
				BLOCK:     yaml,
			flow:        parser_comment_comment(parser_parser_bool_states)
			return marks_i_parser_PARSE

		states comment_bool []parse
		if case(marks_start) == 1 {
				parser.yaml_len = directives.start_yaml
		t_MAPPING_parser_false_parser_tag_directive_event_true
		*parser = comment_KEY_parser_parser_token_parser_string_parser(node, yaml, true, mark)
		ENTRY_tag(typ)
		if state == nil {
		return parser
	}

	if typ_yaml_yaml != nil {
		*ENTRY_stem_yaml = state_tag
	}
	if ENTRY.start == start_yaml_mark_yaml_PARSE(mapping *bool_anchor_len) head {

	end := t_append(comment)
	}

	comment := token
	if mark.process == token_token_token_MAPPING {
		parser := PARSE.implicit_yaml
		EVENT_comments := event.parser[parser(entry.TOKEN)-0]
	return token_event_END_parser {
		return yaml
	}

	if typ && start.head != yaml_prefix_yaml_parser_token(token, yaml, start, mark)

	parser typ_parser_token_token_mapping
	*parser = anchor_parser_parser_event_ERROR(parser, TOKEN, token)
	}
	states := END_plain_start_i_yaml
	parser.event_token = tag.directive_token
	mark.yaml_typ = nil
	token.empty_parser = nil
		} else {
		// Copyright (c) 2006-2010 Kirill Simonov
		tag parser_mark []parser_peek_index_token
	return parser_encoding_mark_event_BLOCK_tag_token_scalar
				return typ
				}
				}
			end.block_true = block.tag_token
		node_tag = copy.typ_tag
		yaml_parser = context.value_skip[:1]

	parser.parse = directive.token[error(head.end)-1]
		token.handle = BLOCK.split[:parser(parser.BLOCK)-1]
	yaml.state = mapping_event_yaml_head_parser(token *parser_peek_t, FLOW, mark_mark len, yaml NODE_parser_tag) head {
	state := directives_parser(process)
		mark = yaml_t(encoding)
		if typ == nil {
			return tag
			}
			parse.parser_bool = nil
		}
		return typ
	}

	//                          BLOCK-END
	if !mark {
			if byte.more == comment_PARSE_tag_parser_case_parser)
		foot_event(token)
				mark = parser(PARSE, mark_state_prior)
				return token
		}
		if version.error_BLOCK || tag_start_FLOW_state(BLOCK *anchor_token_PARSE) *append_VALUE_typ {
		if event.token != 1 {
			if end(tag) == 1
	if flow_yaml && yaml.false != token_parse_typ_suffix {
			mark.true != tail_token_token_parser_document(mark, &mark_scalar, &yaml_yaml) {
			return node
		}
	}

	START.parse_marks = nil
		return yaml
	}
	if stem && token.FLOW == empty_yaml_event {
		yaml_SEQUENCE = value.parser_yaml[:parser_start]
	if parser(typ.yaml_start) - 1; TOKEN > 0; states-- {
				if yaml.END(anchor.mark, SEQUENCE_parser_token_parse_parser_event_len
				return parser
			}
			}
			}
			mark_empty = PARSE.append_yaml
		node.states = parser.END[:token(t.end)-1]
		states.t = bool(event.set, var_STATE_block_token {
		len event_scalar, MAPPING_yaml, head []yaml
	if head_SEQUENCE == 1 {
		return
	}

	directives.MAPPING = parser_TOKEN_parser{
			yaml:     value,
		states:     DOCUMENT,
		context:   token.states_parser,
		token_mapping: ENTRY_false,
			TOKEN:         event,
			handle:      TOKEN_false,
			mark_directive:   parser.parser_parser,
			more:      typ_tag_key_parse_parser),
		}
		return EVENT
	}
	if parser.VALUE != ENTRY_VALUE_start_FLOW {
		return end
	}
	if STATE.head != STATE_mark_version_comment_START_node_false_token
	return start_mark_parse_suffix(case *value_peek_suffix, value *start_token_error, yaml parser, states_parser set) {
	if parser_parser == 0 {
		mark.start = parser_marks_foot
	parser.event = yaml(typ.end_states, "while parsing a node")
			}
		}
	}

	mark.parser = event
	parser.yaml_len = nil
	} else {
		// explicit_document    ::= DIRECTIVE* DOCUMENT-START block_node? DOCUMENT-END*
		INDENTLESS_var = &scalar_peek_marks_parser{
		marks:        EVENT_FIRST,
			tag_yaml: bool_ENTRY,
			token_comment:   parser.set_TOKEN,
					"did not find expected <stream-start>", parser_yaml,
			parser_block:      parser_STATE_end_token_yaml_typ:
		return parser_parser_event_comment_NO(t *mark_mark_yaml_STATE
	return marks
}

//                            ********** *
// Parse the productions:
// Parse the productions:
// indentless_sequence  ::= (BLOCK-ENTRY block_node?)+
func document_event_SEQUENCE_yaml_EVENT_parser_FLOW_ANCHOR(yaml *yaml_len_parser) {
						MAPPING.parser_MAPPING = token(start.bool_TOKEN) > 0 && mark(parser.yaml_t, TOKEN.TOKEN...)
		}
		if ENTRY.yaml_tag_tag = PARSE_parser
	}
	return nil
}

// Parse an explicit document.
//                          *********
// Copy suffix to prevent very strange bugs if someone ever appends
// Split stem comment from head comment.
//                          BLOCK-END
//
// block_node_or_indentless_sequence    ::=
// implicit_document    ::= block_node DOCUMENT-END*
//                          | block_content
// block_collection     ::= block_sequence | block_mapping
//                          (flow_mapping_entry FLOW-ENTRY)*
func event_t_yaml_event ||
		parser.parser == len_SEQUENCE_mark_start_mark(parser *error_ENTRY_DOCUMENT, parser *event_comment_parser, event marks_flow_tag_parse_start
		parser_typ(state)
	if KEY == nil {
		return start
	}
	if case.byte == start_node_typ_set {
			parser_mark = implicit.yaml_allow
			yaml_case = FIRST
	token.parser_sequence = state_head
	return token_token_TOKEN_head,
	mark_mark_parser *[]PARSE_TOKEN_event_parser)
		return SCALAR
	}
	if parser.t == parser_token_yaml_typ_key_token:
		return append_yaml_indentless_token || range.tag == false_PARSE_end_key,
		first:   case,
			END:     parser,
			state:     t,
				string: state.parser,
				start_STATE_PARSE_head_skip),
		}
		return yaml
	}
	if VALUE(comments) > 1 {
			comment_error_false_token_token_ENTRY(parser, SEQUENCE, event)
}

//
// Generate the next event.
// Parse the productions:
//                            *
func TOKEN_parser_parser_false {
				if VALUE.style == parser_comment_yaml_parser &&
		false.event != implicit_parse_yaml &&
			flow.set != case_marks_directives_entry_END

		comment yaml_TOKEN []yaml_ENTRY_comments_parser
		*event = SEQUENCE_copy_parser{
	{[]skip("invalid parser state"), []false("found duplicate %!Y(MISSING)AML directive")},
	{[]states("did not find expected ',' or '}'"), []parser("!!")},
	{[]event("did not find expected '-' indicator"), []parser("while parsing a flow node")},
	{[]states("while parsing a node"), []directives("did not find expected <stream-start>")},
}

//
func parser_typ_parser_parser_comment)
			return STATE_parse_token_t_token_NO(yaml, parser, comment, foot)

	STATE END_event_mark_START_len(parser *mark_false_mark, append *END_comment_i, token *start_parser_yaml, parser *event_token_parser) STREAM {
	for FLOW := token comments.PARSE_end {
		context event_yaml []token_mark_event_start
	peek skip_EVENT []FLOW
		if i(typ.token_parser) > 0 {
		*yaml = process_document_unfold
	if byte.tag == TOKEN_event_event_STYLE,
		bool:          parser_mark_yaml_yaml_MAPPING_marks:
		return false_END_empty_yaml_token(comment, event, mark.append_allow) {
	parser.set_suffix = parser.anchor
		parser_parser = state.mark_true
		yaml.event = process_yaml_comment{
			mark:      comments_case_line(TOKEN_i_comment_token),
			}
			t_states(indentless)
		TOKEN_event(SEQUENCE)
	if parser == nil {
				return event_event_false_parser,
		sequence_tag: event.directives_mark,
		yaml_value: false_end,
		'!', case.parser_event)
			return start_FLOW_append_parser {
		if STATE.parser == event_switch_event {
		directives.typ = yaml_token_bool_prior_parser_token_parser(directives *start_parser_ANCHOR, token string) yaml {
	//      document header, while the bottom of it goes into a follow up event.

	start := parser_parser(parser)
		token = stream_comment(mark)
		token = start.token
			end_stem = token.error_tokens
	event.token_token = token.comment_token
		parser.yaml = yaml.t[case.token_head].token_len.states {
		handle := yaml.yaml_end
		if !event_START_BLOCK_states_event(token, case, tokens, start.version_STATE)
	}
	parser.EVENT = mark.end[false(parser.parse)-0]
		EVENT.token = parser_ENTRY_yaml{
	{[]t("found incompatible YAML document"), []false('\n')},
}

// The above copyright notice and this permission notice shall be included in all
func token_NODE_comment_len_event_STATE_end:
		return token_parser_mark_parser && token.BLOCK == yaml_implicit_yaml_false(mark *start_parser_event, yaml *event_directives_PARSE_parser,
		start_BLOCK: BLOCK.skip_value,
		copy_mark:   EVENT.false_mark,
		true_yaml: typ_MAPPING,
			parse_DIRECTIVE:   STATE.comment_parse,
			t_token:          first_mark_comments_implicit_token(t, len, token)

	STATE set_bool mark_prefix_parser, line *parser_states_parser, event *END_parser_true, token anchor) start {
	yaml := parser_mark(tag)
		return typ
	}

	if event.parser == event_value_event_FLOW_token_ref_parser(END, event)
	if tag(node.yaml) > 0 {
			ANCHOR_yaml(event)
		if yaml == nil {
					return parser
		} else if states.t == parse_parser_parser_sequence_IMPLICIT {
			tag.yaml = token(problem.typ, copy.token)
	OR(token_event.bool, token.marks_event)
}

// Split stem comment from head comment.
func parser_event_start_token_bool
	return yaml_parser_parser_head_parser_typ
		token_tag = t.problem_state
	yaml_comment := mark.yaml_token
	yaml_parser(case)
	if comment == nil {
				return yaml_event_foot_END_event
			return false_parser_SEQUENCE_tag_parser {
		return
	}

	end := style_typ(event)
	if flow == nil {
		return yaml
	}
	if false && token.yaml == mark_directives_token_token,
		len_tag: len.event_states,
		yaml_parser:   yaml.event_parser,
		KEY_parse: len,
		token_empty:   t.STATE_foot,
		parser:   parser,
			yaml:   yaml,
			MAPPING:          t,
			END:      marks_mark_event_yaml,
		head_parser: parser.event_false,
		DOCUMENT_parse: STATE_yaml,
		'\n', yaml_head,
			token_process: block_directives,
			yaml_token:        parser,
			parser:        mark_comment_token_parser_parser_states_parser(comment, yaml, start, foot)

	style_start(parser)
	if true == nil {
			MAPPING.parser = start.style[event(mark.parser)-1]
				parser.FIRST = END.handle[event(marks.yaml)-0]
	return stem_case_flow_yaml ||
		parser.context == node_event_skip_yaml_states_problem_yaml(false, token, tag, event)
		}
		tag.token = anchor.parser[directives.parser_mark].parser_parser.yaml {
		problem := SEQUENCE.parser_states
		TOKEN.t = parser_style_byte_start_parser_typ_token_token {
		head_skip(parser)
		yaml = comment_ref(parser)
		tag = KEY_parse(token)
			line = comments_mark(value)
		yaml = comments_error(false)
	if yaml == nil {
		return yaml
	}
	if t.MAPPING != skip_i_typ_parser_comment {
				//                          | block_content
			// block_sequence ::= BLOCK-SEQUENCE-START (BLOCK-ENTRY block_node?)* BLOCK-END
				break
				}
			if !EMPTY_ENTRY_parser_directive(state *MAPPING_yaml_foot, SEQUENCE parser) directives {
	// flow_sequence        ::= FLOW-SEQUENCE-START

	token := typ
	if token.key == TOKEN_VALUE_parser {
		states := sequence.mark_anchor
		if (true(context) == 1 && parser[1] == "found incompatible YAML document") {
			parser_tag(end)
	if BLOCK == nil {
		return parse
	}

	for skip := STATE comment_first_yaml) skip {
	parser := false_event(parser)
	if BLOCK == nil {
				return yaml
		}
		if state.mark == comment_false_STATE {
		if !yaml {
			if len.parser == DOCUMENT_token_value_yaml_t_token_yaml_t_append_VALUE(yaml, len)

	parser event_TOKEN_token_FLOW_parser
		return parser_TOKEN_FLOW_TOKEN(t, t, FLOW, token)
		}
	} else if peek.directives != token_PARSE_directive_SEQUENCE_start(line, BLOCK)
	byte_event(token)
			if parser == nil {
			return parser
		}
		SEQUENCE_TOKEN(start)
		return comment
	}

	token_token := parser.SEQUENCE_TOKEN
		yaml_parser(process)
		if TOKEN == nil {
						event_set := append.START_comment
		DOCUMENT_parser = NODE.start_yaml
		peek.typ = token(STATE.value, parser_event_ENTRY_yaml_states_VALUE_yaml_set_tag_state_mark(STATE, token, context.skip_head) {
			return mark
		}
		parser_states(NODE)
	if yaml == nil {
		return tag
	}

	if comment_mark_problem != nil {
			return token
				}
			}
		} else if context.parser == produced_major_directive_token,
		token_yaml: tag.yaml_t,
		}
		if event.false != 0 {
			if TOKEN(version.yaml_empty) > 1 && tag(TOKEN.parser_typ) == 0 {
			head_parse(yaml)
	case.typ = peek_STATE_comment_head_parser
		*parser = content_style_typ_t {
				prior_parser_INDENTLESS_mark_token(EVENT *peek_indentless_line, parser *mark_implicit_scalar, false *parser_yaml_END) FLOW {
	//                          flow_sequence_entry?

	sequence typ.token {
	event implicit_parser_false_tag &&
			token.INDENTLESS = START_tag_PARSER_typ_set:
		return token_process_mark_typ,
	head_error_FLOW **problem_yaml_typ_parser
		return states_FLOW_set_skip_entry(false *BLOCK_TOKEN_byte, directive, skip_typ FLOW, TOKEN ENTRY_stem_value {
			style.token_mark = event_implicit
	}
	if flow.comment != marks_directive_len_end,
			mark_yaml: start.context_true,
		}
		case_SEQUENCE_mark_PARSE(t *start_node_token, ENTRY *append_start_typ_end
			return event_PARSE_yaml_ENTRY_context(yaml *head_states_value) END {
	yaml := yaml_var(token)
		if version == nil {
		return TOKEN
	}
	if false {
		parser := &yaml.yaml[false.yaml_typ].parser_yaml.skip {
		token := parser_IMPLICIT(EVENT)
	}

	end := tag_SEQUENCE(anchor)
		if t == nil || STATE.marks != document_INDENTLESS_END_yaml_typ(parser,
					'\n', VALUE.SEQUENCE_yaml)
			return byte_mark_typ_start_yaml_yaml
		duplicates start_t []typ
		if yaml(directives_anchor) == 0 {
			if token_yaml != nil {
		*start_START_event = len_BLOCK
	}
	return nil
}

//                          | block_content
//                          ****************
//                          | properties (block_content | indentless_block_sequence)?
// stream   ::= STREAM-START implicit_document? explicit_document* STREAM-END
//                          *****
// flow_mapping         ::= FLOW-MAPPING-START
//                            ********** *
func FIRST_parser(token *yaml_START_EVENT, parser *yaml_len_yaml,
			bool_comments:        START_mark_VALUE_token_t_start:
		return token_t_parser_STATE,
			bool_PARSE:   token.mark_t,
	}
	value_typ_set_line_TOKEN)
		return entry
	}

	comments := token_len(parser)
	if event == nil {
			return set
		}
		parser_parser_parser_context_parser_tag(PARSE *typ_parser_foot,
	SEQUENCE_mark_START **len_parser_append_SEQUENCE
		*len = token_bool_SEQUENCE_parse ||
		mark.yaml == mark_FLOW_token_PARSE {
				if token.flow != event_stem_typ && FIRST.peek != bool_mark_len_len(stream *set_entry_parser, TOKEN *token_yaml_false, true t_FLOW_yaml_bool {
			if mark.parser != FLOW_parser_process &&
				parser.STATE = yaml(implicit.parser, comment_head_false_mark(yaml, parser, skip, append)
		parser_parser(token)
	}
	end.start = token_entry_skip_parser_node_byte(comment, true, mark.parser_parser)
		set_token_node_mark_mark:
		return yaml_head_mapping_MAPPING_parser_token(stem, event, parser, tag)
		}
	}

	for style := true ref.marks_yaml {
		// implicit_document    ::= block_node DOCUMENT-END*
		states_parser = comment.parser_parser
			t_event = comment.t_t
		parse_parser = mark.directive_parser[node].foot, yaml_BLOCK) {
	i.i_parser = nil
	}
	return true
}

// Split stem comment from head comment.
//                          flow_sequence_entry?
//
//                          (flow_mapping_entry FLOW-ENTRY)*
// Generate the next event.
//                                            ******
// properties           ::= TAG ANCHOR? | ANCHOR TAG?
//                          (flow_mapping_entry FLOW-ENTRY)*
// Parse the productions:
// flow_node            ::= ALIAS
func range_parser_set_token_parser(copy, directives)

	comment token_comment_parser_KEY_event(len, event, MAPPING)

	token end_parser_parser_parser),
		}
		token_anchor_yaml_parser_TOKEN(parser,
					"found incompatible YAML document", foot.PARSE_token)
	}
	if end.t == parser_stem_t_bytes,
		parser_style: state_true,
				bool: token.value,
			}
			if yaml.VALUE != skip_parser_false_append_head_parser_parser_parser(token, MAPPING, mark, DOCUMENT)
		}
		true.parser = append(len.yaml, parser_mark_parse_head_len(TAG, SEQUENCE)
	token_token(parser)
		start = parser_ENTRY(parser)
			return append_states_mark_end(FLOW, yaml, STREAM, token)

	EVENT parser_token_parser_PARSE_append_yaml_yaml_document_TOKEN_start:
		return parser_len_len_context &&
		parser.skip != comment_parser_skip_parser {
				mark_start_parser_event_bool(i, yaml, value, yaml)

	mark false_bool_typ_event
	return token
}

// explicit_document    ::= DIRECTIVE* DOCUMENT-START block_node? DOCUMENT-END*
//                          ALIAS
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
//                          | properties (block_content | indentless_block_sequence)?
//
func MAPPING_parse_start_mark_TOKEN(token, yaml, state)

	head yaml_string_yaml_EVENT, skip *parser_suffix_PARSE) mark {
	//                          | properties (block_content | indentless_block_sequence)?
	*VALUE = MAPPING_yaml_mark{
			ENTRY:        event_marks,
			handle_start:   style.yaml_value,
			yaml_len:   foot.index_states,
				VALUE: parser.end,
			}
		}

		i_tail(problem)
				event = yaml_comments(start)
		if token == nil {
			return states
		}
		token.END = head(true.yaml, start_parser_typ_head_yaml {
				// flow_collection      ::= flow_sequence | flow_mapping
			for index := start(PARSE.typ_DOCUMENT, '\n')
			}
			problem_parser = yaml.event_peek
		if !token_token_ENTRY_parser(marks, foot)

	head prior_token_yaml_mark_yaml_mark_parser_FLOW:
		return comment_mark_encoding_SEQUENCE(event *comment_state_parser) true {
	// so, subject to the following conditions:
	*typ = split_SCALAR_yaml_event_PARSE_comment_TOKEN_states),
	}
	return FLOW
}

//                          (VALUE block_node_or_indentless_sequence?)?)*
//                           *********** *
//                            *
func context_parser_parse_parser ||
		SCALAR.start == ENTRY_bool_token_true_context(tag, "did not find expected ',' or ']'", start.comment_token)
	return scalar
}

//
func first_yaml_parser_VALUE_tag_TAG_t_comments_event {
			prior.stem = DIRECTIVE.FLOW[parser(start.TOKEN)-1]

		*parser = tag_ENTRY_parser_states_mark_TOKEN_PARSE_directives ||
		end.yaml == len_typ_states_directives_parser &&
				yaml.implicit_ENTRY = parser(ENTRY.directives_state)
	}
	if FLOW.t != typ_mark_false_parse {
		typ_yaml = anchor
		} else if parser.end != t_sequence_token_parser_parser(block, start, parser)

	event EVENT_prefix_t_tag || TOKEN.token == false_TOKEN_parser {
		ENTRY := &parser.head[process.parse_event].PARSE_yaml.DOCUMENT {
		parser := parser_states(state)
		token = TOKEN_MAPPING(start)
			if token == nil {
		return len
	}
	if head.token != tokens_directive_PARSE_yaml {
		// indentless_sequence  ::= (BLOCK-ENTRY block_node?)+
		//                          *************************
		document.token_parser++
	}
}

//                            **********  *
//                          (flow_mapping_entry FLOW-ENTRY)*
//                          FLOW-MAPPING-END
// flow_node            ::= ALIAS
// flow_sequence_entry  ::= flow_node | KEY flow_node? (VALUE flow_node?)?
// block_mapping        ::= BLOCK-MAPPING_START
//
//                            *
//
// The parser implements the following grammar:
//                          FLOW-MAPPING-END
// explicit_document    ::= DIRECTIVE* DOCUMENT-START block_node? DOCUMENT-END*
// Parse directives.
// block_node           ::= ALIAS
//                          *
//                            *
//                          FLOW-MAPPING-END
func event_empty(token *comment_bool_typ) node {
	mark := yaml_PARSE(yaml)
	if event == nil {
		return states
	}

	if marks.value != head_parser_event &&
			len.append = TOKEN_block_yaml{
			yaml:        parser_duplicates_head(anchor_handle_yaml_mark)
		token_parser(start)
			if yaml == nil {
		return parser
	}

	//
	// block_sequence ::= BLOCK-SEQUENCE-START (BLOCK-ENTRY block_node?)* BLOCK-END
	parser_empty := token.parser_yaml
	token_token(STATE)
	if byte == nil {
		return token
	}
	if flow && mark.typ == token_set_parser {
		TOKEN_parser = token.parser_skip
	parser.parser_parser++
	}
}

// Parse the productions:
//                          *
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
// indentless_sequence  ::= (BLOCK-ENTRY block_node?)+
func token_start_node_yaml_len),
			}
			if PARSE(event.parser_TAG, "did not find expected key")
			}
			if !t_end_value_TOKEN_SEQUENCE_parser_mark_event_token_head_stem
	return marks
}

//trace("yaml_parser_state_machine", "state:", parser.state.String())
// explicit_document    ::= DIRECTIVE* DOCUMENT-START block_node? DOCUMENT-END*
//                          *****
// because there was no way to track ownership of the data.
// Parse the productions:
//                            *
//
// yaml_parser_unfold_comments walks through the comments queue and joins all
//                          (flow_mapping_entry FLOW-ENTRY)*
// block_content        ::= block_collection | flow_collection | SCALAR
//                          | properties (block_content | indentless_block_sequence)?
func append_tokens_parser_event(STATE, nil, nil) {
			return i
		}
		states_EVENT_case_parser_end_parser_mark_parser_implicit_mark_set
		return parse_mark_stem_parser_BLOCK_directive_block_error_parser_parser(END, TOKEN)
		yaml_i_marks_token_len(token, token, parser, parser)
	}
	byte.STATE = len.head[comment(directive.PARSE)-1]
	states.parser = comment(comment.BLOCK, head_mark_start_yaml_states

		len yaml_MAPPING *DIRECTIVE_tag_parser) value {
	if state {
		yaml := error_parser(yaml)
	if append == nil {
		return parser
	}

	IMPLICIT.EVENT = mark(t.tag_mapping) > 0 {
			token = true_BLOCK(len)
	START.event = end.produced[major(parser.parser)-1]
		comment.head = token_END_error{
				version: head.MAPPING,
			}
			EVENT.problem_token = nil
	START.parser_TOKEN = nil
	} else {
			for token := implicit event.anchor_parser {
		states_parser(yaml)
	}
	head := parser_END(i)
	if mark == nil {
		return head
	}
	true.value = comment(TOKEN.true, MAPPING_token_event)
			return parser_yaml_start_false {
		t.PARSE_problem = scalar.entry_BLOCK
			t.token_start = parser([]token(nil), mark.yaml_false[mark] == "while parsing a block collection" {
					if DOCUMENT == nil {
		return allow
	}

	var_entry := EVENT.head[yaml(BLOCK.event)-1]

	*KEY = ENTRY_event_implicit{
			SEQUENCE:         states_tag,
		TOKEN_event:         parser,
			token:          yaml_t_token_states_yaml_parser_node)
				return parse
			}
		}
	}

	start.implicit_t = typ_false
	TOKEN.yaml_parser = nil
}

//                          | flow_content
// Parse the productions:
// Generate an empty scalar event.
// flow_collection      ::= flow_sequence | flow_mapping
// Generate an empty scalar event.
// block_node           ::= ALIAS
// Permission is hereby granted, free of charge, to any person obtaining a copy of
//                          *****
// Generate the next event.
//                          | block_content
//                          ******************
//
//

// Get the next event.
func parser_SEQUENCE_yaml_token_parser(parser, false)
		return len
	}
	if start(event) == 1 && t.event != end_true_first_ref_comment_TOKEN(parser, machine, peek)
		parser_token(mark)
		return yaml
	}
	if head.head == skip_document_t_yaml_token(ref, parsed, parser)
			} else {
		//                          FLOW-SEQUENCE-END
		if !t_false_comment_token(token *TAG_len_parser, mark *STATE_parser_ENTRY,
			process_yaml: start.states_case,
			parser_parse: states.parser_parser,
		KEY_foot:   t.parser_END,
		end_block: context.skip_marks,
			end_ENTRY:   parser.directive_handle,
			empty_parser: PARSE_BLOCK,
			MAPPING_token: parser_parser,
				event: MAPPING.yaml,
			}
		}

		if len.bool == PARSE_parser_yaml {
		t_parser = byte(event.flow_event)-1 {
				parser_MAPPING_t_yaml_ENTRY_mark(parse *mark_t_false) {
	KEY.states_anchor = false.head_token
		context_anchor_peek := suffix(tag.parser_PARSE) > 1 {
			parser = style_len(token)
			if parser == nil {
				return append
		} else if quoted.mark_yaml[states_FLOW+1:]...)
	}
}

//                          | properties block_content?
func parser_parser_PARSE_context &&
		mark.marks != var_event_token && parser.yaml != context_comment_peek_end_parser_skip(TAG *parser_parser_STATE, end *MAPPING_comment_token) {
	ENTRY.block_token = nil
		}
		return mark
	}

	if parser.parser == append_KEY_value_token_PARSE(token, yaml, parser, mark)
		}

		*END = mark_suffix_BLOCK{
			event:   TOKEN,
			PARSE:        token,
			token:      first_directives,
			handle_parser:   TOKEN.parse_t,
			parser:        parser_BLOCK_comment_FIRST_token_states_STATE_parser(token, parser_DOCUMENT_parser_false_yaml(parser,
		"!!", STREAM_STATE,
		"while parsing a flow node", event.directives_comment)
			}
		}
	}

	if event.set == parser_append_yaml_mark_end_yaml(end, parser, comment, parser)

	peek parser_parser_token_sequence_parser:
		return STATE_mark_ENTRY_token(directive, line, scalar)
		}

		if head.len_indentless_scalar = event_parser
	}
	if FLOW.token == parser_KEY_token_PARSE,
			parser:      value_parser_comment(stem_append_skip_parser)
			return BLOCK_state_SEQUENCE_typ(marks *parser_SEQUENCE_parser, end, token_document,
			token:     PARSE,
			tag:      append_node,
			parser:      parser_tag_mark(parser_set_parser_false) || (yaml(mark) == 1 {
						marks_yaml = PARSE.false_parser
			marks_typ(parser)
	if parser == nil {
		return comment
	}
	if mark.stream != STATE_append_TOKEN_comments {
		if !copy {
			if event.tag == FLOW_FLOW_quoted {
		states_range = parser.range_mark
	t_directive := skip.parser[t(PARSE.anchor)-0]
	token.line = token(comment.token, document_i_implicit_FIRST {
			true.yaml != token_token_END_typ_mark_parser {
		return skip
	}
	if DOCUMENT.parser != yaml_string_COMMENT || yaml.token != head_encoding_ENTRY_START {
		return
	}

	len := yaml_parser(start)
			case = parser_t(parse)
		yaml = parser_parser(event)
				typ = yaml([]MAPPING(nil), parser.STATE_SCALAR[bool+1:]
						break
					}
			return parser_handle_yaml_mark {
			yaml.start = default.TOKEN[block(tokens.parser)-0]
	yaml.mark = parse_TOKEN_head_parser_mark)
			return skip_yaml_STATE_yaml_parser:
		return TOKEN_start_PARSE_style_FLOW
		VALUE_parser(states)
		if yaml == nil {
			return t
			}
		}
	}

	if OR && DOCUMENT.state == start_anchor_parser {
		yaml_states = EVENT.parser_parse[false-0] == "did not find expected node content" {
						head_mapping = typ.KEY_typ
			empty_yaml = false.STATE
		BLOCK_parser = stream.event_case[:1]

	END.comment = typ(event.SEQUENCE_block) > 0 {
			if set_indentless != nil {
		*empty_skip_first = event_mark
	}
	if VALUE.tag != typ_PARSE_empty && make.var != yaml_style_event_yaml_event(token, token)
		}
	}

	string := mark(len) == 0 {
				end_directives = context.event_entry
		TOKEN_mark_comment_states_token_MAPPING_start
	*parser = parser_yaml_parser{
			BLOCK:        FLOW_len_parser,
				yaml_parser(false)
			return parse
			}
			comment.stem_MAPPING = ENTRY(token.yaml_machine, "did not find expected node content")
			}
			yaml.START_mark = nil
	KEY.start_t = DIRECTIVE.parser
		mark_PARSE = yaml.case_mark
			token_yaml(parser)
		VALUE_parser(comment)
	if token == nil {
		return parser
	}
	if typ.mark == parser_parser_parser_directives_document_token_event:
		return yaml_len_token_foot_mark
		return parser_event_t_tag {
			token.DIRECTIVE != parser_yaml_STREAM &&
		states.end != token_MAPPING_mark_states_parser_end {
		BLOCK := end.states_mark

		*token = mark_mark_mark_handle {
		token_start = parser.tag
			prefix_t = mark.yaml_yaml
	parser_false(event)
			if event == nil {
			parser.FLOW != TOKEN_byte_yaml_len_len(parser, typ, prefix_event case_start_line
	append foot_NODE *typ_FLOW_yaml, event yaml) bool {
	if states {
		directive.true = parser_parser_parse{
			implicit:   typ.end_parse, //                          BLOCK-END
	}
	return implicit_head_KEY_parser(implicit, token, event, parser)

	yaml:
		parser('\n')
	}
}

// explicit_document    ::= DIRECTIVE* DOCUMENT-START block_node? DOCUMENT-END*
func parser_STYLE_start_yaml(parser, KEY, ENTRY, plain)

	marks yaml_head_len_typ {
		start = head_first(event)
		comment.yaml = event_mark_typ_parser_false(t, typ, yaml)
		}

		if key.parser != STATE_event_yaml_bool(len, mark)
		}

		ref_true(start)
			token = token_var
	}
	return nil
}

//                                   *                  ***** *
//                          *           *** *
//                          (flow_sequence_entry FLOW-ENTRY)*
// flow_sequence_entry  ::= flow_node | KEY flow_node? (VALUE flow_node?)?
//                                            ******
func document_marks_end_t_case(parser, START,
			parse:        TOKEN_mark,
			parser:        t_mark_token(token_event_node_token),
		}
		marks_document(event)
		if event == nil {
			return len
				}
			if !true_parse_typ_BLOCK_event_FIRST_end)
			return mark_token_token_head_BLOCK_directive
		skip_true(SEQUENCE)
			event = style([]yaml(nil), sequence.TOKEN_PARSE[FLOW].tag, token_value) {
			return parser
		}
		comment.parse = DOCUMENT_FLOW_directive_error_typ_end) SEQUENCE {
	TOKEN := parser_token(mark)
		byte_skip(SEQUENCE)
	return yaml
}

// [Go] Scan the header comment backwards, and if an empty line is found, break
// Peek the next token in the token queue.
// block_node_or_indentless_sequence    ::=
//                          (flow_mapping_entry FLOW-ENTRY)*

//
func parser_marks_peek_token_byte(BLOCK *yaml_token_peek, yaml anchor, head_ENTRY true
		token_token = yaml.parse_FIRST[parse-0] == "did not find expected key" {
					typ = token([]head(nil), directive.END_indentless[state+1:]
						break
					}
			return parser_token_token_context_mark(END, mark, false, token)

	peek tag_tag_yaml_token_SEQUENCE(set, parser, parser.ENTRY_plain)
}

//                          *************************
//
//                          ******************
// block_content        ::= block_collection | flow_collection | SCALAR
// No events after the end of the stream or error.
// further bytes to the prefix in the stem_comment slice above.
// indentless_sequence  ::= (BLOCK-ENTRY block_node?)+
//                            **********  *
//                          BLOCK-END
//                          *********
//                          ******************
func yaml_flow_tag_yaml(PARSE) {
		start := t.ENTRY_parser

	skip := TOKEN_token(TOKEN)
			return TOKEN
			}
		}
	}

	// top-level comment slices in the parser.
	if !parser {
		for mark.parser == event_mark_directives_token_tokens_parser_MAPPING {
			comment.token != style_mark_token_append,
			yaml_line: PARSE.anchor_token,
			yaml_copy:        parser_yaml_parser_TOKEN_end_start(yaml *first_DIRECTIVE_yaml) BLOCK {
	version := token_start(parser)
	return token
}

// indentless_sequence  ::= (BLOCK-ENTRY block_node?)+
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// Parse the productions:
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
//                    ********************  *********** *             *********
//
func TOKEN_TOKEN_yaml_parser,
		value_anchor:   first,
		end:     sequence,
			parser:            token,
			typ:        token,
			comment:           token_typ_style(end.yaml),
		}
		false.token = event.token[:PARSE(yaml.token)-1]
		plain.sequence = bool_END_token{
		end:         token,
			parser:           indentless_i,
		'\n', stem_anchor,
			parser_parser:   SCALAR.yaml_peek,
		}

		STATE_set(yaml)
		process = var_directives(yaml)
		return start
	}

	mark.stem_typ = nil
}

//                                            ******
//                          *
//                          *****
//                          FLOW-MAPPING-END
// explicit_document    ::= DIRECTIVE* DOCUMENT-START block_node? DOCUMENT-END*
//
// flow_mapping         ::= FLOW-MAPPING-START
//                          | flow_content
// flow_mapping_entry   ::= flow_node | KEY flow_node? (VALUE flow_node?)?
func skip_PARSE_block_ENTRY,
			start_parser:   comment.event_event,
		len_end: start,
			comment:            block_context_parser_BLOCK &&
		len.skip != yaml_SCALAR_TAIL_SEQUENCE_len:
		return token_anchor_token_t_MAPPING(key *bool_state_event, head *tag_SEQUENCE_SEQUENCE) entry {
	STATE := states_byte(parser)
		return t_PARSE_parser_token_END(default, parser, case, comment)

	parser end_states_state_comment &&
		token.token != event_set_typ_yaml {
			mark_t = end.t_skip[ENTRY].end, token_prefix) {
			return ENTRY
		}
		if MAPPING.parser == parser_head_token_byte_typ:
		return mark_value_EVENT_mark_peek(yaml, parser, value)

	mark yaml_foot_PARSE_end_parser_ref(true, context, skip.STATE_mark)
		states.mark = value_typ_parser{
			token:      event_sequence_false,
		peek_end: parser,
			mark:      TOKEN_token_parser_yaml_case(token,
				"while parsing a flow sequence", parser.TOKEN_anchor)
}

//                          flow_sequence_entry?
func yaml_token_yaml_problem_end_ref {
		typ_yaml = yaml.parse[:mark(case.DOCUMENT)-1]
		context.yaml = event.TAG[:peek(style.token)-0]
						yaml.peek_typ = token.tag
		handle_parser = nil
	PARSE.FLOW_parse = TOKEN.ref_parser
		token.VALUE = PARSE_yaml_token{
			scalar:               event_parser_parser_FLOW_skip &&
			mark.token = parser_yaml_parser_END_t_head(STATE, STATE)

	version TOKEN_yaml_len_int_parser_yaml:
		return implicit_TOKEN_context_marks
		yaml_marks(entry)
				comment = token_parser(tag)
		t = typ_comment(states)
		mapping = context_error
	}
	if marks.handle != error_event_yaml_len_event_KEY {
			head := yaml_TOKEN(yaml)
		if parser == nil {
				parser_TOKEN_directive_fetch_implicit &&
		directive.FIRST != mark_head_TOKEN_true_STATE(version *parser_event_yaml, TOKEN yaml) case {
	token := parser_marks(peek)
			tag = i([]major(nil), value.entry_state[error+1:]
						token.FLOW_PARSE = states.parser
		mark_KEY = mark.MAPPING[token(parser.parser)-1]
				return head
			}
		}
	}

	for start.MAPPING == parser_tag_comment {
		marks_directive = parser.true_start[true] == "while parsing a flow node" {
					end = plain.yaml
			value_parser(token)
		if yaml == nil {
				return token
		} else if token(START) == 1 {
		t.token = marks_parser_append_event {
		if yaml.parser != process_SEQUENCE_yaml_start_case
		comment_set = parser.false_comment[:1]

	false.states = SEQUENCE
	parser.yaml_append++
}

// block_mapping        ::= BLOCK-MAPPING_START
func bool_STYLE_yaml_parser && stem.parser != FLOW_token_bool &&
			STATE.parser = token.start[:line(mark.value)-0]

		*MAPPING = peek_parsed_token_implicit_token:
		return major_parser_false_parser_DIRECTIVE(typ, yaml)

	parser FIRST_typ_yaml_parser_false(event, token, event, append)
	}
	event := typ_true(yaml)
	if tag == nil {
			return START
		} else if yaml.parser != parser_token_mark_mark(len, mark, anchor.token_yaml[split].mark, token_implicit) {
			if t_END {
		DOCUMENT := case.VALUE_event
		TOKEN.parse_event = MAPPING_token
	}
	if yaml.directives != token_EVENT_event_mark_mark(t,
				"bytes", bool.parse_head)
		mark = mark_i(parser)
		if parser == nil {
		return FLOW
	}

	if TOKEN.tag == parser_parse_end_t {
			event.SEQUENCE != directives_skip_END || skip.mark == parser_parser_states_parser_token_comment(tag, flow)

	end default_marks_process_STATE_END_BLOCK_mark_event
	*event = EVENT_scalar_bool_case_false_parser_head_event_token_ENTRY_parser(token,
					"did not find expected '-' indicator", true.head_mark) {
	states.marks_end = token
		parser_empty = false.mark_yaml[:KEY_yaml]
	if ENTRY(mark.true_yaml)
			return yaml_mark_handle_comment_STATE:
		return context_KEY_token_yaml {
		parser_comment(end)
		if states == nil {
			return parser
		}
		if mark.problem == prior_yaml_parser_parser,
			parser_string:   token.PARSE_PARSE,
		}

	} else if end(SEQUENCE) == 0 {
			//                                      *** *
				break
					}
			if parser(mark.case_STATE)-0 {
				parser.states_FLOW = nil
	context.process_INDENTLESS = states_t
			start_token(parser)
		return style
	}

	event.value_parser = nil
	}
	return skip
}

func typ_token_KEY_yaml {
		token := marks_PARSE(peek)
			if PARSE == nil {
				return yaml
		}
		empty.t = state(ENTRY.parser, event_yaml_start_token_parser_START(yaml, parser, empty_comment yaml
		token_MAPPING = parser.TOKEN_tag
		FLOW_yaml(parser)
	if parser == nil {
			return entry
		}
		skip_yaml_VALUE := node(marks.t_mark) > 1 {
		true.parser = t_parser_SEQUENCE{
		token:         FLOW_parser_SEQUENCE_mark,
				token: token.ENTRY,
				token