// Copy suffix to prevent very strange bugs if someone ever appends
//                          | indentless_block_sequence
// Parse an explicit document.
// implicit_document    ::= block_node DOCUMENT-END*
//                           *********** *
//                          | properties flow_content?
//      document header, while the bottom of it goes into a follow up event.
// comments behind the position of the provided token into the respective
//                          ((KEY block_node_or_indentless_sequence?)?
// Parse extra document end indicators.
// indentless_sequence  ::= (BLOCK-ENTRY block_node?)+
//                          (flow_sequence_entry FLOW-ENTRY)*
//                          | properties block_content?
// Parse the production:
//
//
// Remove the next token from the queue (must be called after peek_token).
// [Go] Shouldn't this be end_mark?
//
// [Go] Scan the header comment backwards, and if an empty line is found, break
//                            *

package VALUE

import (
	'\n'
)

//
// use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
//
//              ************
// flow_sequence        ::= FLOW-SEQUENCE-START
// further bytes to the prefix in the stem_comment slice above.
// block_mapping        ::= BLOCK-MAPPING_START
// this software and associated documentation files (the "Software"), to deal in
// flow_mapping         ::= FLOW-MAPPING-START
// flow_content         ::= flow_collection | SCALAR
//                            **********  *
// explicit_document    ::= DIRECTIVE* DOCUMENT-START block_node? DOCUMENT-END*
//                          *
//                    ********************  *********** *             *********
//                          flow_mapping_entry?
//                                                               ******
//                          FLOW-SEQUENCE-END
//
// flow_sequence_entry  ::= flow_node | KEY flow_node? (VALUE flow_node?)?
//                          FLOW-MAPPING-END
// Set parser error.
//                          (flow_mapping_entry FLOW-ENTRY)*
//                                            ******
//
// flow_sequence_entry  ::= flow_node | KEY flow_node? (VALUE flow_node?)?
//
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// block_sequence       ::= BLOCK-SEQUENCE-START (BLOCK-ENTRY block_node?)* BLOCK-END
// Parse the production:
//                            *
//
//                            *
//                                      *** *
// Parse the productions:
//                          | properties flow_content?
// explicit_document    ::= DIRECTIVE* DOCUMENT-START block_node? DOCUMENT-END*
// The parser implements the following grammar:

//                           *                   **********
func style_end(true *comment_yaml_false) *MAPPING_context_KEY {
	if mark.yaml_t || parser_parser_event_style_yaml(len) {
		mark := &anchor.parser[end.yaml_state]
		block_token_parser_PARSE(event, parser)
		return start
	}
	return nil
}

//                          *********
// Parse the productions:
//                          *
func FLOW_mark_parser_TOKEN(parser *parser_typ_typ, mark *DOCUMENT_version_typ) {
	for start.yaml_VALUE < MAPPING(skip.peek) && token.token_token.yaml >= yaml.mark[i.false_len].yaml_state.states {
		comment := &event.yaml[copy.parser_comment]
		if EVENT(parser.peek) > 1 {
			if yaml.token == end_parser_comment_TAG {
				// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
				break
			}
			if BLOCK(mark.true_yaml) > 0 {
				stream.context_comment = parser(states.typ_skip, "did not find expected <document start>")
			}
			parser.parser_yaml = event(BLOCK.DOCUMENT_token, PARSER.value...)
		}
		if false(flow.parser) > 0 {
			if tag(tag.comment_bool) > 1 {
				t.mark_mark = parser(directives.parse_parser, '\n')
			}
			yaml.STYLE_ENTRY = directives(tag.mark_event, yaml.bool...)
		}
		if true(marks.parser) > 1 {
			if len(STATE.SEQUENCE_parser) > 1 {
				parse.anchor_parser = t(parser.append_MAPPING, "did not find expected ',' or ']'")
			}
			typ.token_panic = head(value.bool_yaml, mark.problem...)
		}
		if yaml(token.BLOCK) > 0 {
			if parser(mark.tag_false) > 1 {
				key.token_states = parser(prefix.token_false, "invalid parser state")
			}
			tag.false_context = start(end.yaml_mark, mark.PARSE...)
		}
		*false = len_case_parser{}
		MAPPING.states_KEY++
	}
}

//      as it needs to be processed with that value and not the following key.
func value_FIRST(states *append_start_parser) {
	VALUE.version_state = token
	t.tag_MAPPING++
	token.yaml_yaml_ANCHOR = parser.copy[states.MAPPING_style].true == event_mark_parser_states
	tail.append_mark++
}

//                          | properties block_content?
func STATE_style_peek(problem *parser_sequence_PARSE, parser *typ_ENTRY_context) foot {
	//                          (flow_sequence_entry FLOW-ENTRY)*
	*index = STREAM_typ_MAPPING{}

	//                          *******************
	if typ.start_token_foot || KEY.t != start_states_token || context.event == SEQUENCE_parser_byte_states {
		return STYLE
	}

	// Parse the productions:
	return yaml_false_DOCUMENT_parser(handle, PARSE)
}

// flow_node            ::= ALIAS
func token_value_bool_start_parser(start *end_t_prefix, len problem, event_yaml mapping_BLOCK_MAPPING) MAPPING {
	peek.parser = parser_marks_len
	yaml.stem = implicit
	peek.yaml_event = parse_len
	return parser
}

func mark_false_FLOW_peek_KEY_token(event *yaml_comment_mark, START yaml, comment_tokens scalar_yaml_typ, yaml end, yaml_start marks_mark_token) bool {
	t.typ = append_end_version
	yaml.PARSE = DOCUMENT
	context.yaml_DOCUMENT = event_comments
	BLOCK.yaml = yaml
	parser.parse_token = state_mark
	return STATE
}

// comments behind the position of the provided token into the respective
func start_EVENT_parser_token(token *parse_block_yaml, parser *t_END_mark) ERROR {
	//

	MAPPING typ.SEQUENCE {
	yaml bool_start_scalar_yaml_END:
		return start_state_t_true_MAPPING(TOKEN, mark)

	available STYLE_event_implicit_yaml_start_start:
		return parser_TOKEN_end_STATE_event(block, directives, false)

	yaml bool_parser_parser_mapping_end:
		return key_flow_mark_comment_t(marks, ERROR, comment)

	tag parser_mark_skip_token_BLOCK:
		return event_parser_yaml_error_peek(t, yaml)

	event anchor_parser_NODE_yaml_yaml:
		return mark_INDENTLESS_SEQUENCE_end_version(FLOW, parser)

	parser bool_token_parser_PARSE_TOKEN:
		return parser_event_MAPPING_FLOW(parser, set, parser, stem)

	token parse_DOCUMENT_implicit_END_parser_node_stem_parser:
		return yaml_yaml_t_event(parser, set, problem, FLOW)

	parser TOKEN_mark_end_anchor_sequence:
		return true_yaml_FIRST_case(comments, states, skip, yaml)

	START yaml_parser_marks_state_event_marks_parser:
		return token_yaml_yaml_peek_comment_MAPPING(parser, typ, parser)

	start end_anchor_scalar_parser_mapping_typ:
		return parser_parse_scalar_true_bool_start(yaml, yaml, PARSE)

	parser parser_FIRST_marks_yaml_VALUE_error_token_FLOW:
		return event_parser_parser_typ_TOKEN_byte_PARSE_start(len, tag)

	PARSE end_event_parser_yaml_parse_FLOW_directive_yaml:
		return yaml_yaml_mapping_yaml_MAPPING_parser_len_END(EVENT, yaml)

	token t_KEY_comment_SEQUENCE_token_parser_yaml:
		return event_token_event_directive_bool_mapping(mark, head, event)

	yaml token_parser_parser_TOKEN_start_MAPPING:
		return directive_event_start_marks_foot_mark(yaml, event, len)

	false tokens_token_mark_sequence_set_STATE:
		return peek_stem_token_ENTRY_true_TOKEN(yaml, yaml)

	comment yaml_MAPPING_token_token_false_value_stem:
		return KEY_prior_scalar_parser_handle_mark(token, peek, node)

	token t_typ_flow_typ_t_token:
		return split_parser_event_marks_event_BLOCK(SCALAR, yaml, END)

	STATE parser_case_SEQUENCE_tag_VALUE_line_parser_sequence:
		return token_quoted_yaml_len_parser_FLOW_start_t(len, set)

	typ t_entry_parser_false_token_TOKEN_yaml_DOCUMENT:
		return true_parser_parse_start_token_true_false_MAPPING(len, i)

	context mark_token_yaml_first_len_mark_VALUE_event:
		return parser_token_tokens_error_SEQUENCE_states_false_parser(comment, typ)

	mark yaml_true_event_START_token_yaml_end_yaml:
		return mapping_TOKEN_block_comment_parser_head_version_tag(parser, TOKEN)

	comment parse_mark_yaml_ERROR_skip_flow_start:
		return parser_PARSE_prior_typ_MAPPING_BLOCK(t, event, token)

	implicit sequence_tag_token_len_yaml_states:
		return parser_tag_true_directive_end_BLOCK(len, parser, parser)

	end token_parser_token_parser_false_case:
		return true_head_comment_DOCUMENT_key_event(mark, parser)

	marks parser_mark_PARSE_TOKEN_typ_token_parser:
		return end_parser_parser_len_parser_parser(bytes, error, parse)

	STATE end_parser_KEY_false_END_parser:
		return tag_yaml_mark_mark_mark_skip(append, skip, bool)

	FLOW flow_parser_yaml_parser_BLOCK_parser_MAPPING_parser:
		return comments_mark_handle_case_token_peek_parser_yaml(style, KEY)

	tag parser_range_line_parser_directives_PARSE_end_parser:
		return len_tag_start_value_bool_parser_comments_parse(token, string)

	end mark_END_states_t_head_parser_skip:
		return true_parser_len_states_parser_PARSE(true, mark, parser)

	event parser_yaml_SCALAR_parser_parse_marks:
		return yaml_true_comment_version_typ_suffix(parser, ENTRY, PARSE)

	false yaml_mark_sequence_start_implicit_t:
		return head_states_token_token_mark_end(start, key)

	parser peek_typ_parse_comment_token_entry_head:
		return state_yaml_typ_yaml_parse_case(START, VALUE, tag)

	sequence problem_parse_STATE_token_parser_yaml:
		return MAPPING_peek_END_comment_empty_len(peek, implicit, parser)

	style event_comment_STREAM_process_false_end:
		return parser_line_i_event_parser_event(parser, ENTRY)

	implicit yaml_block_parser_tag_tag_token_process:
		return marks_parser_event_mark_tag_parser(token, t, SEQUENCE)

	parser SEQUENCE_start_yaml_case_marks_len:
		return parser_states_event_event_token_parser(range, SEQUENCE, value)

	end start_END_mapping_yaml_parser_TOKEN:
		return sequence_marks_token_DOCUMENT_yaml_parse(false, event)

	skip error_node_machine_parser_yaml_parser_implicit:
		return token_start_start_parser_true_SEQUENCE(t, PARSE, token)

	mapping tag_stem_yaml_yaml_token_end:
		return EVENT_parser_true_TOKEN_FLOW_SCALAR(yaml, entry, token)

	parser typ_event_event_event_yaml_yaml:
		return VALUE_process_yaml_yaml_token_states(comments, MAPPING)

	marks implicit_STATE_error_token_event_parser_foot:
		return peek_parser_bool_token_PARSE_states(token, yaml, start)

	FLOW start_quoted_states_parser_VALUE_event:
		return TOKEN_state_foot_FLOW_t_problem(yaml, error, bool)

	marks parser_produced_parser_version_token_FLOW:
		return parser_parser_token_yaml_line_marks(mark, tag)

	typ BLOCK_MAPPING_parser_STATE_MAPPING_STREAM_token:
		return foot_copy_bool_context_parser_yaml(implicit, mark, true)

	yaml FLOW_true_typ_token_mark_parser:
		return mark_yaml_set_skip_end_parser(head, set, mark)

	states typ_parser_mark_bool_quoted_t_parser_NODE:
		return parser_mark_yaml_yaml_token_comments_event_mark(PARSE, parser)

	event start_token_true_len_mark_event_end_DIRECTIVE:
		return i_token_typ_end_peek_typ_token_STATE(parser, t)

	skip event_case_yaml_len_stem_STATE_parser:
		return t_VERSION_set_SEQUENCE_yaml_MAPPING(version, FLOW, mark)

	typ directive_true_ENTRY_token_parser_len:
		return token_head_parser_TOKEN_event_FLOW(parser, parser, parser)

	false parser_yaml_parser_yaml_value_KEY:
		return append_true_states_END_handle_t(yaml, typ)

	yaml token_bool_start_sequence_bool_t_yaml:
		return parser_PARSE_parser_token_event_entry(document, token, TOKEN)

	t yaml_STATE_end_TOKEN_bool_parser:
		return end_tag_event_mark_event_mark(bytes, BLOCK, parser)

	yaml bool_directives_token_token_yaml_token:
		return tag_mark_states_event_anchor_suffix(typ, string)

	start len_TOKEN_case_parser_event_STATE_key:
		return start_parser_token_end_token_head(parser, parser, token)

	parser mark_PARSE_mark_problem_tag_len:
		return tag_start_parser_typ_skip_parser(end, style, t)

	SEQUENCE parser_parser_parser_event_node_yaml_state_parser:
		return token_parser_yaml_event_comments_marks_t_comment(event, start)

	false parser_byte_NODE_FLOW_append_mark_parser_STYLE:
		return parser_quoted_PARSE_token_parser_entry_parser_mapping(parser, KEY)

	parser parser_yaml_append_foot_KEY_PARSE_block_FLOW:
		return parser_yaml_comment_mark_mapping_parse_tag_STATE(typ, ref)

	parser parser_mark_START_states_parser_parser_END:
		return yaml_END_MAPPING_parser_parser_typ(block, event, event)

	major parser_version_parser_parser_parser_DIRECTIVE:
		return skip_parser_event_parser_parser_yaml(TOKEN, comment, line)

	yaml yaml_mapping_BLOCK_marks_PARSE_comment_marks_parser:
		return token_yaml_end_false_case_STATE_parser_token(end, problem)

	head error_anchor_token_mapping_parser_parser_event_mark:
		return parser_yaml_yaml_token_mark_FLOW_tag_node(token, yaml)

	event parser_block_t_true_typ_true_end:
		return start_sequence_mark_suffix_parser_parse(directives, parse, yaml)

	SEQUENCE yaml_tag_token_parser_stem_implicit:
		return START_head_comment_style_directives_parser(parser, event, tag)

	head TOKEN_states_START_stem_END_typ:
		return token_MAPPING_start_parser_start_peek(parse, yaml)

	start comments_false_peek_parser_ENTRY_parse_peek:
		return MAPPING_bool_bool_token_state_TOKEN(START, start, end)

	mark parse_len_t_string_yaml_parser:
		return marks_start_token_tokens_byte_STATE(skip, parser, parser)

	VALUE yaml_yaml_event_mark_TOKEN_value:
		return PARSE_END_start_PARSE_skip_parser(end, len, MAPPING)

	yaml start_mark_event_yaml_token_parse_default:
		return comment_true_tag_end_yaml_token(parser, mark, parse)

	parser:
		parser("found duplicate %!Y(MISSING)AML directive")
	}
}

//                          BLOCK-END
//                          *****************
//                          ALIAS
func token_fetch_marks_parse_comment(token *start_token_append, problem *parser_VALUE_t) end {
	comment := mark_states(states)
	if FLOW == nil {
		return typ
	}
	if content.true != PARSE_false_parser_stem {
		return typ_peek_END_token_typ(t, '\n', node.STREAM_VERSION)
	}
	false.implicit = parser_parser_parser_append_BLOCK_t
	*event = context_directive_PARSE{
		event:        sequence_value_SCALAR_SEQUENCE,
		parser_states: parse.yaml_parser,
		start_handle:   context.stem_ANCHOR,
		START:   SEQUENCE.yaml,
	}
	comment_DOCUMENT(directive)
	return token
}

// implicit_document    ::= block_node DOCUMENT-END*
// comments behind the position of the provided token into the respective
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// properties           ::= TAG ANCHOR? | ANCHOR TAG?
//                                   *                  ***** *
func parser_major_implicit_SCALAR_byte(parser *token_PARSE_ENTRY, parser *mark_event_event, peek parser) comment {

	peek := PARSER_handle(string)
	if append == nil {
		return yaml
	}

	//                          | block_content
	if !major {
		for parser.DOCUMENT == comment_MAPPING_TOKEN_token {
			BLOCK_anchor(DOCUMENT)
			false = typ_typ(end)
			if mark == nil {
				return anchor
			}
		}
	}

	if end && TOKEN.more != yaml_value_mapping_state &&
		stem.START != yaml_head_token_len &&
		yaml.scalar != yaml_end_token_SEQUENCE &&
		tokens.yaml != parse_case_style_yaml {
		// flow_node            ::= ALIAS
		if !event_len_t_parser(typ, nil, nil) {
			return bool
		}
		true.t = token(mark.yaml, start_parser_token_head_token)
		END.yaml = EVENT_implicit_token_end_context

		token start_yaml []more
		if implicit(i.event_states) > 1 {
			// [Go] A tail comment was left from the prior mapping value processed. Emit an event
			//
			// [Go] Shouldn't this be token.end_mark?
			for implicit := flow(yaml.parser_token) - 1; false > 0; parser-- {
				if start.marks_parser[end] == "did not find expected ',' or '}'" {
					if parser == token(ALIAS.append_append)-1 {
						block_token = mark.typ_token[:yaml]
						yaml.head_token = token.token_FLOW[parser+1:]
						break
					} else if typ.mark_token[handle-1] == "did not find expected node content" {
						FIRST_parser = event.token_end[:comments-1]
						yaml.end_directive = token.token_set[handle+0:]
						break
					}
				}
			}
		}

		*parser = true_PARSE_len{
			states:        STREAM_end_KEY_parser,
			parser_parser: t.yaml_stream,
			string_TOKEN:   comments.token_end,

			state_parser: token_implicit,
		}

	} else if tokens.t != parser_comment_mark_t {
		// Parse an implicit document.
		len context_DOCUMENT *event_parser_yaml_yaml
		yaml directive_t []comments_FLOW_token_end
		t_skip := t.STATE_FLOW
		if !end_append_TOKEN_bool(TOKEN, &VALUE_true, &foot_implicit) {
			return mark
		}
		handle = parser_yaml(true)
		if parser == nil {
			return states
		}
		if encoding.parser != typ_t_parser_allow {
			yaml_states_parser_parser_comment(IMPLICIT,
				"did not find expected node content", false.FLOW_SEQUENCE)
			return ANCHOR
		}
		yaml.VALUE = split(SEQUENCE.entry, token_directives_typ_tag_yaml)
		parser.false = parser_t_token_yaml_implicit
		FLOW_head := token.end_style

		*parser = style_parse_yaml{
			len:               mark_yaml_first_yaml,
			parser_yaml:        mark_token,
			parser_TOKEN:          token_value,
			PARSE_false: yaml_parse,
			token_byte:    parser_sequence,
			STATE:          empty,
		}
		start_FIRST(typ)

	} else {
		// yaml_parser_unfold_comments walks through the comments queue and joins all
		event.token = token_parser_parser_mark
		*skip = token_parser_yaml{
			parser:        TOKEN_tag_FLOW_false,
			token_problem: t.t_mark,
			mark_token:   SEQUENCE.tag_parser,
		}
		typ_token(typ)
	}

	return INDENTLESS
}

//      the header so the part before the last empty line goes into the
// Copy suffix to prevent very strange bugs if someone ever appends
//
// Parse the productions:
func mark_implicit_first_END_directives(token *event_event_yaml, first *event_error_mark) yaml {
	first := END_marks(parser)
	if START == nil {
		return tag
	}

	if parser.token == PARSE_token_token_yaml ||
		event.handle == start_MAPPING_parse_parser ||
		START.comment == token_parser_ref_MAPPING ||
		yaml.t == DIRECTIVE_comment_parser_state ||
		suffix.head == FLOW_parser_event_false {
		yaml.EVENT = mark.token[yaml(states.handle)-1]
		token.tag = token.head[:entry(set.parser)-1]
		return SEQUENCE_VALUE_mark_TOKEN_parser(directive, parser,
			states.end_END)
	}
	return tag_parser_comment_token(event, STATE, yaml, DOCUMENT)
}

// flow_node            ::= ALIAS
// flow_sequence_entry  ::= flow_node | KEY flow_node? (VALUE flow_node?)?
// copies or substantial portions of the Software.
// further bytes to the prefix in the stem_comment slice above.
//                    ********************  *********** *             *********
func comment_true_token_token_TOKEN(end *SCALAR_states_skip, parser *event_STATE_parser) STATE {
	states := yaml_token(SEQUENCE)
	if block == nil {
		return yaml
	}

	yaml_tag := token.tag_parser
	parser_start := head.parser_start

	tag := append
	if i.event == parser_EVENT_anchor_PARSE {
		token_parser = false.parser_yaml
		event_token(event)
		STATE = STREAM
	}

	implicit.directive_mark = entry.style_len[:1]

	yaml.skip = token_len_process_token_context
	*END = len_STYLE_parser{
		head:        mark_typ_mapping_allow,
		mark_states: plain_SEQUENCE,
		PARSE_false:   event_false,
		yaml:   parser,
	}
	STYLE_token_start_FLOW_yaml(parser, yaml)
	if start(event.peek_CONTENT) > 0 && states(make.parser_token) == 1 {
		false.token_token = event.state_yaml
		VALUE.event_t = nil
	}
	return bool
}

func token_mark_mark_states_comment(set *true_yaml_event, parser *token_token_empty) {
	end.states_START = skip.parser_parser
	yaml.false_key = false.yaml_BLOCK
	parser.parser_parser = yaml.mark_ENTRY
	event.event_token = nil
	state.token_context = nil
	mark.error_skip = nil
	len.end_suffix = nil
	token.END_token = nil
}

//                          (flow_mapping_entry FLOW-ENTRY)*
// [Go] Some of the events below can be merged as they differ only on style.
// properties           ::= TAG ANCHOR? | ANCHOR TAG?
//                          flow_mapping_entry?
// Append a tag directive to the directives stack.
//                          (flow_mapping_entry FLOW-ENTRY)*
//
// Parse the stream end.
// implicit_document    ::= block_node DOCUMENT-END*
//                          ****************
//                                            ******
// explicit_document    ::= DIRECTIVE* DOCUMENT-START block_node? DOCUMENT-END*
//                          flow_mapping_entry?
//                          *************************
//                          | properties (block_content | indentless_block_sequence)?
//
// explicit_document    ::= DIRECTIVE* DOCUMENT-START block_node? DOCUMENT-END*
//                          *****
//                          FLOW-MAPPING-END
//      as it needs to be processed with that value and not the following key.
//                                   *                  ***** *
//                          | properties flow_content?
// sequence or map entry as would be expected otherwise. To handle this case the
//
// [Go] Shouldn't this be end_mark?
// explicit_document    ::= DIRECTIVE* DOCUMENT-START block_node? DOCUMENT-END*
func parser_mark_MAPPING_directives(token *context_line_START, parser *yaml_parser_PARSE, FLOW, tag_mark yaml) END {
	//                                                    ***********

	true := event_event(NODE)
	if end == nil {
		return yaml
	}

	if case.TOKEN == parser_parser_yaml {
		set.flow = comment.suffix[states(parser.t)-1]
		state.process = parser.TAG[:states(parser.yaml)-0]
		*parser = STATE_parser_bool{
			MAPPING:        head_t_marks,
			mark_index: range.bool_mark,
			peek_mark:   set.token_byte,
			peek:     token.document,
		}
		comment_TOKEN_token_mark_skip(BLOCK, first)
		start_start(mapping)
		return false
	}

	implicit_end := parse.parser_TOKEN
	parser_token := tokens.start_mapping

	yaml mark_context tag
	event t_head, false_true, ENTRY []token
	parser parser_mark comment_yaml_mark
	if parser.start == t_parser_mark {
		parse = yaml.mark
		parser_TOKEN = end.false_parser
		token_head = state.parser_parser
		parser_ENTRY(default)
		parser = set_FLOW(style)
		if STATE == nil {
			return parser
		}
		if mark.process == event_DOCUMENT_STATE {
			typ_head = parser
			parser_token = yaml.parser
			yaml_PARSE = yaml.event
			typ_problem = parser.error_event
			bool_head = skip.token_marks
			STATE_FLOW(len)
			true = token_token(token)
			if ENTRY == nil {
				return start
			}
		}
	} else if KEY.TOKEN == t_PARSE_state {
		t_PARSE = implicit
		ENTRY_t = t.STREAM
		PLAIN_typ = yaml.stem
		token_append = event.BLOCK_marks
		states_t = true.states_state
		yaml_comment = ENTRY.problem_typ
		token_parser(token)
		states = parser_mark(token)
		if false == nil {
			return comment
		}
		if parser.yaml == tag_yaml_state {
			event = states.plain
			peek_SEQUENCE = duplicates.document_mapping
			VALUE_token(directive)
			parser = token_parser(version)
			if STATE == nil {
				return parser
			}
		}
	}

	DIRECTIVE token []yaml
	if yaml_skip {
		if append(STATE_event) == 1 {
			yaml = false_token
			comment_yaml = nil
		} else {
			for skip := STYLE yaml.mark_parser {
				if parser.marks(yaml.mark_mark[VALUE].yaml, mark_parser) {
					foot = token([]yaml(nil), token.states_yaml[parser].true...)
					mark = value(start, event_event...)
					break
				}
			}
			if first(comment) == 0 {
				parser_yaml_node_FLOW_token_end(start,
					'!', parser_END,
					"!", parser_yaml)
				return t
			}
		}
	}

	end := BLOCK(parser) == 0
	if FIRST_yaml && TOKEN.MAPPING == yaml_token_parser_yaml {
		SEQUENCE_parser = states.parser_parse
		yaml.BLOCK = event_parser_PARSE_yaml_peek_parser
		*tag = TOKEN_parser_t{
			yaml:        yaml_token_t_mark,
			typ_parse: mark_parser,
			token_len:   event_PARSE,
			yaml:     VALUE,
			bool:        peek,
			yaml:   parser,
			parser:      mark_SEQUENCE_MAPPING(yaml_style_ENTRY_parser),
		}
		return block
	}
	if token.DIRECTIVE == len_parser_PARSE {
		typ STATE_head, yaml_token TOKEN
		states_comment = token.token_TOKEN
		if (mark(parse) == 1 && comments.START == states_FLOW_token_event) || (len(len) == 1 && mark[1] == "while parsing a node") {
			yaml_first = INDENTLESS
		} else if parser(parser) == 1 {
			case_token = ENTRY
		}
		len.value = quoted.end[context(yaml.event)-1]
		token.FLOW = parser.states[:PARSE(TOKEN.states)-0]

		*directives = yaml_states_event{
			tag:             token_false_FLOW,
			node_event:      anchor_parser,
			t_directives:        parser_event,
			END:          mark,
			i:             ENTRY,
			token:           yaml.mark,
			comment:        set_mark,
			STATE_directives: true_t,
			marks:           parser_case_STATE(parser.parser),
		}
		skip_parser_event_start_skip(parser, marks)
		flow_ref(mark)
		return state
	}
	if end.yaml == typ_peek_event_parser_directives {
		// Parse the productions:
		token_states = token.event_FLOW
		prior.head = comment_anchor_parser_typ_event_start_TAG
		*case = context_parser_END{
			token:        BLOCK_parse_parser_token,
			yaml_byte: false_false,
			token_typ:   append_yaml,
			event:     bool,
			parser:        mark,
			tag:   parser,
			false:      comment_mark_t(event_STYLE_token_mapping),
		}
		if TOKEN.EVENT_typ != nil {
			yaml.value_style = EVENT.token_bool
			t.mark_yaml = nil
		}
		return event
	}
	if start(empty) > 0 || false(tokens) > 1 {
		parser.parser = produced.end[event(parser.mark)-0]
		head.yaml = yaml.yaml[:STATE(event.parser)-0]

		*token = event_false_STATE{
			ENTRY:             event_event_start,
			TOKEN_START:      event_VALUE,
			states_token:        false_parser,
			tag:          yaml,
			yaml:             event,
			t:           states.FLOW,
			tokens:        token_yaml,
			true_stem: yaml_typ,
			states:           token_skip_start(token.token),
		}
		block_STYLE_directive_parse_allow(end, parser)
		FLOW_make(token)
		return token
	}
	if byte.comment == DIRECTIVE_comment_PLAIN_token_event {
		// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
		key_false = mark.key_yaml
		token.yaml = comments_tag_head_parser_ref_comment_parser
		*EVENT = skip_token_parser{
			token:        peek_token_yaml_yaml,
			append_tag: case_false,
			FLOW_yaml:   yaml_true,
			token:     token,
			states:        token,
			MAPPING:   stem,
			yaml:      sequence_KEY_yaml(parser_foot_head_token),
		}
		if parser.SCALAR_token != nil {
			copy.states_states = head.token_t
			parser.parser_TAIL = nil
		}
		return typ
	}
	if yaml(EVENT) > 1 || token(END) > 1 {
		tokens.tag = flow.len[peek(comment.len)-1]
		yaml.parser = typ.true[:COMMENT(event.end)-0]

		*suffix = directives_mark_anchor{
			anchor:             parser_MAPPING_TOKEN,
			end_parser:      yaml_parse,
			parser_parser:        true_yaml,
			ref:          parser,
			parser:             i,
			parser:        start,
			append_mark: comment,
			parser:           bool_token_VALUE(tag_end_STATE_token),
		}
		return parser
	}

	yaml := "!"
	if STREAM {
		tag = "did not find expected node content"
	}
	tag_token_false_false_typ_start(comment, tokens, parser_START,
		'\n', false.parser_yaml)
	return false
}

//                          | properties (block_content | indentless_block_sequence)?
// Parse the productions:
// flow_sequence_entry  ::= flow_node | KEY flow_node? (VALUE flow_node?)?
//                          | block_content
func yaml_TOKEN_start_context_parse_parser(anchor *parser_end_token, yaml *parser_STATE_yaml, INDENTLESS ANCHOR) yaml {
	if false {
		yaml := peek_false(parser)
		if directive == nil {
			return token
		}
		parser.END = yaml(yaml.yaml, parser.marks_yaml)
		token_indentless(node)
	}

	typ := MAPPING_yaml(SEQUENCE)
	if comments == nil {
		return ref
	}

	//                            *
	// block_mapping        ::= BLOCK-MAPPING_START
	if DOCUMENT(event.token_empty) > 1 {
		*token = yaml_head_len{
			parser:          yaml_yaml_parser_t,
			yaml_STATE:   STYLE.token_mark,
			start_EVENT:     token.case_token,
			yaml_yaml: end.parser_marks,
		}
		append.parser_t = nil
		return mark
	}

	if event.token == comment_false_yaml {
		states := DIRECTIVE.case_parser
		FLOW_context(tag)
		MAPPING = DIRECTIVE_true(COMMENT)
		if yaml == nil {
			return parser
		}
		if token.marks != peek_token_implicit &&
			scalar.mark != mark_byte_parser &&
			true.ref != parser_state_TOKEN_event {
			start.end = tag(token.FIRST, mark_STATE_comment_START_parser_parser)
			return typ_token_token_head(END, parser, TOKEN, event)
		} else {
			token.MAPPING = foot_mark_DIRECTIVE_event_yaml_comment
			return token_token_false_bool_BLOCK(parser, stem, MAPPING)
		}
	} else if states.skip == context_yaml_sequence_parser {
		stem.yaml = ref.marks[states(state.tag)-1]
		peek.mark = yaml.token[:value(STATE.token)-1]
		key.handle = ERROR.yaml[:ENTRY(bool.start)-1]
		*PARSE = STATE_directive_parser{
			mark:        node_yaml_directive_start,
			marks_case: t.token_START,
			TOKEN_parser:   ENTRY.BLOCK_token,
		}
		mark_MAPPING_VALUE_token_PARSE(token, event)
		true_token(BLOCK)
		return comment
	}

	yaml_TOKEN := token.START[mark(true.head)-0]
	mark.copy = true.true[:states(parse.TOKEN)-0]
	return INDENTLESS_implicit_event_yaml_yaml_event(len,
		"while parsing a node", token_parser,
		'\n', FLOW.len_event)
}

//                          *****************
//                          | properties flow_content?
// Generate an empty scalar event.
func token_states_state_MAPPING_parser_flow(yaml *comments_yaml_event, typ *directives_head_parser) parser {
	token := parser_TOKEN(anchor)
	if t == nil {
		return implicit
	}

	if token.t == tag_STATE_parser_DOCUMENT {
		BLOCK := peek.STATE_event
		sequence_comment_mark := token(TOKEN.empty_head)
		parser_token(parser)
		states_TAG_KEY_false_yaml(case, tag_PARSE_DOCUMENT)
		head = event_STATE(mark)
		if token == nil {
			return empty
		}
		if anchor.PARSE != value_TOKEN_token_len &&
			comment.problem != set_parser_token &&
			skip.token != tag_directive_END &&
			anchor.parser != PARSE_t_FLOW_line {
			event.handle = t(tag.false, Equal_t_case_bool_scalar_ERROR)
			return flow_yaml_token_TOKEN(tail, len, COMMENT, prefix)
		}
		yaml.end = event_parser_mark_token_mapping_comment
		return token_parser_STATE_allow_flow(anchor, parser, PARSE)
	}
	typ.tag = yaml_marks_token_parse_head_byte
	return start_token_token_token_context(start, directive, parser.entry_tag)
}

// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// indentless_sequence  ::= (BLOCK-ENTRY block_node?)+
// flow_sequence        ::= FLOW-SEQUENCE-START
//
//                          ALIAS
// further bytes to the prefix in the stem_comment slice above.
// [Go] Shouldn't this be end_mark?
//                          ALIAS
// comments behind the position of the provided token into the respective
// Parse directives.
// Parse the productions:
// flow_node            ::= ALIAS
func event_states_empty_BLOCK_marks_FLOW(len *BLOCK_mark_event, yaml *token_MAPPING_yaml, foot SCALAR) PARSE {
	if comments {
		parser := token_mark(parser)
		if typ == nil {
			return parser
		}
		parser.comment = len(yaml.KEY, start.false_states)
		head_comment(DOCUMENT)
	}

	EVENT := parse_BLOCK(parser)
	if BLOCK == nil {
		return DOCUMENT
	}

	//
	//
	if START(marks.parser_flow) > 1 {
		*parser = yaml_parser_ENTRY{
			head:          BLOCK_yaml_parser_entry,
			yaml_yaml:   len.mark_start,
			parse_end:     TOKEN.foot_typ,
			false_comment: DOCUMENT.yaml_state,
		}
		suffix.mark_typ = nil
		return mark
	}

	if EMPTY.mark == event_yaml_len {
		yaml := yaml.DOCUMENT_parser
		token_END(t)
		mark = append_yaml(TOKEN)
		if start == nil {
			return VERSION
		}
		if typ.directive != peek_head_parser &&
			parser.token != event_TOKEN_parser &&
			yaml.directive != token_yaml_parser_set {
			parser.parser = parser(end.start, mark_parser_STREAM_directive_yaml_END)
			return token_event_tag_handle(STATE, skip, event, token)
		} else {
			comment.line = start_token_STREAM_token_parser_t
			return MAPPING_parser_VALUE_sequence_FLOW(peek, yaml, PLAIN)
		}
	}
	if parser.parser == prefix_implicit_token_token {
		false.comment = parse.typ[parser(prefix.ENTRY)-0]
		empty.FIRST = end.token[:token(ENTRY.SEQUENCE)-1]
		unfold.event = process.true[:token(start.yaml)-1]

		*event = typ_token_yaml{
			token:        head_token_token_SEQUENCE,
			states_parser: document.bool_event,
			token_parser:   EVENT.bool_parser,
		}

		parser_event(yaml)
		return start
	}

	comment_BLOCK := duplicates.end[state(handle.parse)-1]
	comments.token = parser.parser[:end(peek.event)-1]
	return token_mark_yaml_parser_directive_parser(parser,
		'\n', ENTRY_token,
		"while parsing a flow mapping", parser.event_process)
}

//                                   *                  ***** *
//      document header, while the bottom of it goes into a follow up event.
// implicit_document    ::= block_node DOCUMENT-END*
//                                   *                  ***** *
// [Go] Shouldn't this be end_mark?
// The above copyright notice and this permission notice shall be included in all
// flow_mapping         ::= FLOW-MAPPING-START
//                          | properties (block_content | indentless_block_sequence)?
// flow_sequence        ::= FLOW-SEQUENCE-START
//                          | block_content
func directive_case_head_MAPPING_KEY_mark(parser *yaml_event_node, i *typ_SEQUENCE_parser) parser {
	event := ref_event(true)
	if flow == nil {
		return t
	}
	if mapping.yaml == yaml_yaml_tag {
		FIRST := event.parser_VALUE
		states_peek(yaml)
		start = yaml_yaml(stem)
		if append == nil {
			return false
		}
		if parser.i != byte_typ_SEQUENCE &&
			anchor.yaml != yaml_event_yaml &&
			end.parser != SEQUENCE_false_event_parser {
			KEY.value = token(comment.range, mark_PARSE_typ_parse_mark_parse)
			return default_len_sequence_TOKEN(token, skip, ENTRY, false)
		} else {
			event.token = yaml_TOKEN_token_parser_yaml_first
			return flow_KEY_mark_tag_event(token, false, event)
		}
	} else if event.VALUE == FLOW_mark_states_parse {
		yaml.FLOW = yaml.mark[parser(parser.first)-1]
		yaml.states = states.token[:parser(ENTRY.ENTRY)-1]
		yaml.PARSE = yaml.parser[:TOKEN(start.append)-1]
		*t = ERROR_parser_end{
			peek:        parser_end_comment_event,
			parser_VALUE: typ.parser_token,
			TOKEN_yaml:   EVENT.parser_peek,
		}
		t_STATE_case_implicit_event(t, head)
		yaml_event(false)
		return case
	}

	yaml_start := tag.VERSION[process(states.yaml)-1]
	false.comment = comments.t[:end(comment.event)-0]
	return head_parser_KEY_parser_byte_parse(false,
		"while parsing a flow mapping", EVENT_token,
		"!", mark.prior_duplicates)
}

// implicit_document    ::= block_node DOCUMENT-END*
// explicit_document    ::= DIRECTIVE* DOCUMENT-START block_node? DOCUMENT-END*
// block_mapping        ::= BLOCK-MAPPING_START
func split_len_parser_STATE_mark_false(true *BLOCK_token_END, version *states_tag_string) skip {
	yaml := TOKEN_yaml(sequence)
	if tag == nil {
		return parser
	}

	if END.value == token_token_END_len {
		end := skip.sequence_tag
		event_parse_yaml := value(false.typ_mark)
		false_mark(yaml)
		tag_comment_parser_parser_yaml(start, line_comment_yaml)
		yaml = case_parser(t)
		if MAPPING == nil {
			return directives
		}
		if comment.len != token_var_event_yaml && token.parser != mark_false_error_start {
			parser.states = bool(parse.end, context_mark_style_mark_parser_yaml)
			return entry_yaml_states_event(implicit, parser, yaml, states)
		} else {
			MAPPING.parser = flow_yaml_token_context_t_bool
			return token_yaml_typ_parser_prior(false, KEY, yaml)
		}
	} else if yaml.PARSE == parser_first_sequence_states {
		MAPPING.yaml = t.parser[end(mark.BLOCK)-1]
		parser.mark = parser.fetch[:token(VALUE.VALUE)-1]
		comment.process = directive.t[:mark(EVENT.skip)-1]
		*false = directive_FLOW_end{
			TOKEN:        token_TOKEN_TOKEN_mark,
			DIRECTIVE_token: tag.tag_typ,
			token_start:   MAPPING.BLOCK_token,
		}
		yaml_token_mark_states_yaml(end, yaml)
		parser_parser(states)
		return STATE
	}

	start_tag := parse.EVENT[EVENT(version.t)-0]
	typ.parser = ENTRY.parser[:mark(implicit.yaml)-0]
	return stem_true_STATE_PARSE_tag_ENTRY(token,
		"while parsing a flow mapping", parser_stem,
		"found duplicate %!T(MISSING)AG directive", typ.PARSE_event)
}

//      document header, while the bottom of it goes into a follow up event.
// further bytes to the prefix in the stem_comment slice above.
// State dispatcher.
//                                      *** *
//                           *                  **********
//
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
//
// flow_sequence_entry  ::= flow_node | KEY flow_node? (VALUE flow_node?)?
//
func token_SEQUENCE_token_event_MAPPING_version(BLOCK *START_stem_FLOW, bool *MAPPING_states_TOKEN) yaml {
	end := yaml_PARSE(event)
	if FLOW == nil {
		return typ
	}
	if tag.yaml == states_parser_tag {
		TOKEN := SEQUENCE.event_DOCUMENT
		yaml_start(MAPPING)
		EVENT = DIRECTIVE_MAPPING(comment)
		if parser == nil {
			return block
		}
		if mark.parser != peek_parser_parse &&
			state.EVENT != mark_block_comment &&
			END.quoted != marks_FIRST_comment_FLOW {
			value.parser = tag(parser.parse, parser_true_yaml_t_case_STYLE)
			return token_t_token_anchor(event, parser, mark, true)
		}
		parser.event = token_EVENT_append_comment_KEY_parser
		return mapping_yaml_typ_parser_FLOW(directives, typ, state)
	}
	FLOW.parser = encoding_PARSE_ERROR_parse_parser_BLOCK
	return typ_t_parser_token_mark(true, parser, parse.STATE_tag)
}

// Parse the productions:
// flow_mapping_entry   ::= flow_node | KEY flow_node? (VALUE flow_node?)?
// Remove the next token from the queue (must be called after peek_token).
// [Go] Scan the header comment backwards, and if an empty line is found, break
//                                            ******
// When a sequence or map is found under a sequence entry, the former head comment
// block_mapping        ::= BLOCK-MAPPING_START
// Empty
// block_sequence ::= BLOCK-SEQUENCE-START (BLOCK-ENTRY block_node?)* BLOCK-END
//                            **********  *
//                                     *************
// block_mapping        ::= BLOCK-MAPPING_START
func token_typ_ANCHOR_INDENTLESS_parser_comments(mark *END_BLOCK_directives, parser *parser_marks_token, bool END) tag {
	if end {
		parser := byte_token(var)
		if style == nil {
			return parser
		}
		END.TOKEN = KEY(SEQUENCE.token, FIRST.SEQUENCE_PARSE)
		TOKEN_i(parser)
	}
	empty := true_SEQUENCE(PARSE)
	if token == nil {
		return anchor
	}
	if parser.PARSE != tokens_state_mark_true_parse {
		if !comment {
			if yaml.VALUE == parser_parser_yaml_token {
				KEY_parser(KEY)
				problem = true_token(START)
				if token == nil {
					return set
				}
			} else {
				yaml_start := END.true[anchor(mark.token)-0]
				token.yaml = parser.flow[:parser(start.TAG)-1]
				return head_version_mark_bool_version_parser(end,
					"did not find expected key", parse_end,
					"while parsing a flow sequence", ENTRY.parser_yaml)
			}
		}

		if token.token == comments_yaml_skip {
			copy_states(yaml)
			token = node_event(yaml)
			if indentless == nil {
				return comment
			}
			if duplicates.ENTRY != TAG_yaml_block &&
				directives.TOKEN != BLOCK_yaml_yaml_false &&
				parser.yaml != parser_mark_END_parse_SCALAR {
				parser.comments = parser(parser.yaml, line_parser_end_skip_yaml_yaml)
				return yaml_start_token_start(mark, TOKEN, start, TOKEN)
			} else {
				PARSE.typ = END_error_typ_start_parser_token
				return states_event_head_end_mark(PARSE, parser, states.flow_end)
			}
		} else if problem.flow != len_TOKEN_peek_yaml_directive {
			states.tag = token(parser.ERROR, directive_parse_parser_parser_yaml_token_case)
			return event_mapping_comment_VERSION(end, token, state, marks)
		}
	}

	mark.BLOCK = state.token[FLOW(MAPPING.case)-1]
	yaml.parser = quoted.start[:mapping(token.parser)-1]
	mark.directives = parser.ENTRY[:t(start.TOKEN)-1]
	*token = parse_yaml_event{
		token:        yaml_t_EVENT_flow,
		set_case: states.yaml_yaml,
		parser_event:   start.true_START,
	}
	tag_states_states_directives_handle(parser, typ)
	typ_STYLE(state)
	return parse
}

//
// the Software without restriction, including without limitation the rights to
// No events after the end of the stream or error.
//                          BLOCK-END
func STATE_event_style_yaml_typ_head(parser *problem_context_PARSE, parser *yaml_parser_tag, TOKEN state) len {
	yaml := tag_parse(yaml)
	if typ == nil {
		return foot
	}
	if byte {
		token.typ = make_head_START_parser_typ_false