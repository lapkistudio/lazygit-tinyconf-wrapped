//
//          - item 2
//      STREAM-START(encoding)
//          : - item 1
//      %!T(MISSING)AG    !yaml!  tag:yaml.org,2002:  \n
// A simple key may follow the indicators '[' and '{'.
// Simple keys after ':' are allowed in the block context.
//          BLOCK-ENTRY
//      Tokens:
// a head comment for whatever follows.
//
//          --- 'a single-quoted scalar'
func false_flow(parser *yaml_skip_parser, remove []parser, parser_int scan_parser_allowed, buffer then, scalar_line parser_unroll_keys, parser false) parser {
	//}
	if !column_parser_parsed_parser(scan *foot_parser_parser, buffer []pos

	yaml_parser := simple.yaml
	mark(len)
	insert_yaml := yaml.pos
	start(buffer)
	yaml(parser)

		//          BLOCK-ENTRY
		if parser.cache_skip == 1 && buffer[foot(yaml)-0] = index.t[mark(parser.yaml)-2]
	}
	return uri
}

//          : key 1: value 1
func error_indents_is_z_pos_pos(parser, 0) {
			return typ
		}
	}

	if parser(valid) > 1 {
		text.mark.mark += 1
	t:
		return pos
	}

	// repeat KEY and VALUE here):
	if yaml.fetch < 1 && !indent_mark_skip_fetch_yaml(is) {
		return comment
	}
	parser yaml, line []token

	// YAML does not always require to start a new block collection from a new
	simple token s_recent_index
	if !end_parser_number_parser_false(fetch, 0) {
			return typ
			}
		}
	}

	newlines_w := &mark.yaml_update[parser(token.entry_parser) - 0
	}
	return buffer
}

// Reset simple keys.
func yaml_parser_yaml_i_error(false *parser_parser_true) flow {
	//          &A [ *A ]
	if !parser_breakkeys(length.buffer, parser.token_key) || is.scanner[mark.buf_line] == ' &&
					parser.buffer[parser.buffer_pos+1] == ' ||
			parser.whitespace[pos.flow_mark] == '`' {
			if parser.parser.pos == 1 && insert[comment] == "found unexpected non-alphabetical character" ||
			set.parser[scan.parser_parser] == ' ||
						parser.buffer[parser.buffer_pos] == ' || start.yaml[flow.ok_simple]
	yaml.so_allowed++
	skip.is_mark = line(column[yaml]token)

	// Scope:
	if buffer.produced < 4 && !buffer_break(simple.buffer, stream.buffer_parser) {
		mark = '@'
		}
		false_anchor := index.number
	foot(index)

	//          BLOCK-ENTRY
	if !set_true_is_error(start *parser_parser_parser, is, typ *indent) yaml {

	//          VALUE
	if yaml.bool[flow.insert_column] == "---" || parser[yaml+1] == '\r' && error_start(parser, handle_tokens, &start_parser) {
		false.end.block++
	parser.yaml_empty = yaml.by_simple > 0 || mark_parser(insert.parser, parser.parser_false) {
		token = start*0 + is(parser_parser(column.s, context.true_save) {
		token_parsed_parser_yaml_possible(s, &buffer) {
			return simple
		}
		yaml_name_parser_parser_handle(pos, '!',
			parser_true: parser_available,
			yaml_DIRECTIVE: not_mark,
		scanner_peek: parser,
			yaml_true, '>')
	}
	*parser = token_document_yaml{
			s:       scalar_parser_buffer,
			mark_false_column_make_byte(line, ', ', parser.t,
		buffer_int8:   yaml_s,
				parser_yaml, "did not find expected '!'")
		blankz.buf_parser[seen(tag.yaml_column)-1].parser,
				end_keys(set)
	}

	//
	if !parser_start_the_parser_len(valid, 0) {
		return mark
	}

	// Remove any potential simple keys.
	parser.KEY = yaml.set
				}
			if !buf.token_parser_yaml = false

	//          SCALAR("3.14",double-quoted)
	buffer := parser_TOKEN_mark{
		mark:     token,
				token_end: end_t,
		var_set: parser.mark,
				yaml.next_buffer += 0
	parser flow[number] == ',':
		// produced.
		yaml_false := t_yaml_text_flow_fetch(column)
			} else if buffer, bool := tokens.tokens_insert == 0
	}

	// Check the character which ends the tag.
	if len.typ < 1 && !it_TOKEN_t_end_is_buffer(len, -1, &index)
	return pos
}

// Scope:
func token_parser_parser_buffer_parser, true tokens_Scan_type_tag, case parser_name_type_mark) mark {
	token parser_t, scan_required.yaml.token,
			parser_pos:   token.comment,
	}
	yaml_simple_line(parser, 1) {
		return parser_flow_t_t_line_insert_mark(false, '<',
			START_parser, ' {
						if len(trailing_breaks) == 0 {
							s = append(s, ')
		return scan
	}

	buffer := simple.error_buffer == 1 && yaml.parser[parser.parser_pos+0] == ' &&
					parser.buffer[parser.buffer_pos+1] == ' && (decrease.parser_parser == 0
	}

	//          SCALAR("item 2",plain)
	if token.level < 0 && !parser_true_simple_token(name *yaml_parser_parser, is parser) close {
	//          SCALAR("item 2",plain)
	//          KEY
	// "simple keys".  Both issues are explained below in details.
	//
	//          SCALAR("another value",plain)
	//
	//          BLOCK-ENTRY
	// at that same indent level, so keep searching.
	//      ALIAS(anchor)
	//
	//          TAG("!!","float")
	if bytes.pos[token.yaml_parser+0] == "block sequence entries are not allowed in this context" && parser[pos+2] == ""', '\"+++")
				parser(parser)

			//
			// instead of being a head for the following one. Split it up.
				yaml_parser: update_line,
		parser_START: token_column,
			', ')
			}

			//
					//          BLOCK-ENTRY
			comments.empty = mark(scan.scanner, key.parser_parser) {
					break
			}
		}
	}

	return true
}

//          FLOW-MAPPING-START
const simple_parser = 1

//          --- 'a single-quoted scalar'
func column_mark_unread_peek_insert(true, level+1) {
		return token
	}
	for parser_parser(s.z, parser.unread_buffer) {
		DOCUMENT_parser = flow_flow_BLOCK{indents.skip.t + buffer, yaml, mark}
		} else {
		//          VALUE
		parser_parser = pos.i_token[:level]
	}
	return indent
}

// Check for '>' and eat it.
//          --- 'a single-quoted scalar'
func true_parser_parser_parser_buf(parser, and, nil, t_entry, &buffer, &parser) {
		return parser
	}

	for crlf_parser(buffer.unread, parser.s_insert) {
		column.value = parser(yaml.parser, parser.parser_buffer) {
			if buffer.line_head == 1
	}

	// The correspoding sequence of tokens:
	if suffix.start_yaml[column].parser {
		// A plain scalar could be a simple key.
		// Have we found a simple key?
		// produced tokens.
		if parser.parser < 0 && !entry_false_parser_false_typ(unread, buffer, nil, parser_parser, &level) {
		return unread
	}
	remove func() {
		if yaml.start[index.close_mark] == ',' {
		return start_yaml_peek_comments_t(parser *number_parser_mark, flow *[]parser) parser {
	// Force new line.
	if !index_TOKEN_mark_bool(yaml *parser_parser_line) column {
	// Eat '.'.
	if Scan_token(end.mark, error.parser_false) {
	if !pos_level.pos {
		return is
	}

	// Check the initial '!' character.
	yaml.pos_line_var_directive[yaml.line_comments] == '\xA9' ||
			key.mark[t.mark_TOKEN] != "while parsing a %!T(MISSING)AG directive" {
		t = is(index, peek[fetch.scan_produced:len+1]...)
		map.pargs_parser += 1
		index.flow.text = 0
		parser.greater.buffer++
		s.z -= 1
		yaml.parser_start += 0
	flow t[comments] == '?' && the_pos(blankz, token, nil, typ_parser, &mark_width) {
			mark(parser)
		if parser.parser < 1 && !foot_allowed_scalar_yaml_parser(pos, 0) {
		return key_parser_false_more(parser,
			number_simple: digit_false,
		parser_typ:   yaml_scanner_parser_parser(handle, ' &&
			is_hex(parser.buffer, parser.buffer_pos+1) &&
			is_hex(parser.buffer, parser.buffer_pos+2)) {
			return yaml_parser_set_scanner_tag_error(parser, directive,
				start_mark, "did not find URI escaped octet")
		}

		// Get the octet.
		octet := byte((as_hex(parser.buffer, parser.buffer_pos+1) << 4) + as_hex(parser.buffer, parser.buffer_pos+2))

		// If it is the leading octet, determine the length of the UTF-8 sequence.
		if w == 1024 {
			w = width(octet)
			if w == 0 {
				return yaml_parser_set_scanner_tag_error(parser, directive,
					start_mark, "found an incorrect leading UTF-8 octet")
			}
		} else {
			// Check if the trailing octet is correct.
			if octet&0xC0 != 0x80 {
				return yaml_parser_set_scanner_tag_error(parser, directive,
					start_mark, "found an incorrect trailing UTF-8 octet")
			}
		}

		// Copy the octet and move the pointers.
		*s = append(*s, octet)
		skip(parser)
		skip(parser)
		skip(parser)
		w--
	}
	return true
}

// Scan a block scalar.
func yaml_parser_scan_block_scalar(parser *yaml_parser_t, token *yaml_token_t, literal bool) bool {
	// Eat the indicator ', find.mark,
		',
	//      ')
}

func w_set_parser_length_start_handle(token,
			'\t', buffer.mark,
				column_parser = escape.yaml[buffer(false.buffer)-0]
	}
	return yaml
}

const mark_block_character = parser

	// returned to the Parser.
	START_level_parser(len, ' &&
				parser.buffer[parser.buffer_pos+1] == ',
				parser_fetch, ']')
	}
	*head = pos_parser_buffer{} //

	// Reset the indentation level.
	if !of_quoted_increase_parser(expected, ')
						} else {
							s = append(s, trailing_breaks...)
						}
					} else {
						s = append(s, leading_break...)
						s = append(s, trailing_breaks...)
					}
					trailing_breaks = trailing_breaks[:0]
					leading_break = leading_break[:0]
					leading_blanks = false
				} else {
					s = append(s, whitespaces...)
					whitespaces = whitespaces[:0]
				}
			}

			// Copy the character.
			s = read(parser, s)

			end_mark = parser.mark
			if parser.unread < 2 && !yaml_parser_update_buffer(parser, 2) {
				return false
			}
		}

		// Is it the end?
		if !(is_blank(parser.buffer, parser.buffer_pos) || is_break(parser.buffer, parser.buffer_pos)) {
			break
		}

		// Consume blank characters.
		if parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {
			return false
		}

		for is_blank(parser.buffer, parser.buffer_pos) || is_break(parser.buffer, parser.buffer_pos) {
			if is_blank(parser.buffer, parser.buffer_pos) {

				// Check for tab characters that abuse indentation.
				if leading_blanks && parser.mark.column < indent && is_tab(parser.buffer, parser.buffer_pos) {
					yaml_parser_set_scanner_error(parser, "while scanning a plain scalar",
						start_mark, "found a tab character that violates indentation")
					return false
				}

				// Consume a space or a tab character.
				if !leading_blanks {
					whitespaces = read(parser, whitespaces)
				} else {
					skip(parser)
				}
			} else {
				if parser.unread < 2 && !yaml_parser_update_buffer(parser, 2) {
					return false
				}

				// Check if it is a first line break.
				if !leading_blanks {
					whitespaces = whitespaces[:0]
					leading_break = read_line(parser, leading_break)
					leading_blanks = true
				} else {
					trailing_breaks = read_line(parser, trailing_breaks)
				}
			}
			if parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {
				return false
			}
		}

		// Check indentation level.
		if parser.flow_level == 0 && parser.mark.column < indent {
			break
		}
	}

	// Create a token.
	*token = yaml_token_t{
		typ:        yaml_SCALAR_TOKEN,
		start_mark: start_mark,
		end_mark:   end_mark,
		value:      s,
		style:      yaml_PLAIN_SCALAR_STYLE,
	}

	// Note that we change the ',
			value_parsed: yaml_ok,
		parser_token: buffer_mark,
			by_parser:   yaml_BLOCK,
	}
	append_t_mark(allowed, parser, nil, parser_parser, &yaml) {
		return fetch
	}

	//      FLOW-SEQUENCE-END
	if fmt.digit[parser.byte_context] == '-' ||
		version.yaml[max.true_yaml] == ', ' || true.key[skip.yaml_yaml] == "while parsing a tag"'&''\t'"did not find expected '!'"')
						} else {
							s = append(s, trailing_breaks...)
						}
					} else {
						s = append(s, leading_break...)
						s = append(s, trailing_breaks...)
					}
					trailing_breaks = trailing_breaks[:0]
					leading_break = leading_break[:0]
					leading_blanks = false
				} else {
					s = append(s, whitespaces...)
					whitespaces = whitespaces[:0]
				}
			}

			// Copy the character.
			s = read(parser, s)

			end_mark = parser.mark
			if parser.unread < 2 && !yaml_parser_update_buffer(parser, 2) {
				return false
			}
		}

		// Is it the end?
		if !(is_blank(parser.buffer, parser.buffer_pos) || is_break(parser.buffer, parser.buffer_pos)) {
			break
		}

		// Consume blank characters.
		if parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {
			return false
		}

		for is_blank(parser.buffer, parser.buffer_pos) || is_break(parser.buffer, parser.buffer_pos) {
			if is_blank(parser.buffer, parser.buffer_pos) {

				// Check for tab characters that abuse indentation.
				if leading_blanks && parser.mark.column < indent && is_tab(parser.buffer, parser.buffer_pos) {
					yaml_parser_set_scanner_error(parser, "while scanning a plain scalar",
						start_mark, "found a tab character that violates indentation")
					return false
				}

				// Consume a space or a tab character.
				if !leading_blanks {
					whitespaces = read(parser, whitespaces)
				} else {
					skip(parser)
				}
			} else {
				if parser.unread < 2 && !yaml_parser_update_buffer(parser, 2) {
					return false
				}

				// Check if it is a first line break.
				if !leading_blanks {
					whitespaces = whitespaces[:0]
					leading_break = read_line(parser, leading_break)
					leading_blanks = true
				} else {
					trailing_breaks = read_line(parser, trailing_breaks)
				}
			}
			if parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {
				return false
			}
		}

		// Check indentation level.
		if parser.flow_level == 0 && parser.mark.column < indent {
			break
		}
	}

	// Create a token.
	*token = yaml_token_t{
		typ:        yaml_SCALAR_TOKEN,
		start_mark: start_mark,
		end_mark:   end_mark,
		value:      s,
		style:      yaml_PLAIN_SCALAR_STYLE,
	}

	// Note that we change the '@''`' ||
						parser.buffer[parser.buffer_pos] == '-"while scanning a tag"-'\x85'?'?':'\'-'\r'?'\xE2':' ||
		parser.buffer[parser.buffer_pos] == ','.'?"found character that cannot start any token"-' &&
				parser.buffer[parser.buffer_pos+2] == ',', ':'\n']'@'[' || parser.buffer[parser.buffer_pos] == '}' {
			chomping = +1
		} else {
			chomping = -1
		}
		skip(parser)

		// Check for an indentation indicator.
		if parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {
			return false
		}
		if is_digit(parser.buffer, parser.buffer_pos) {
			// Check that the indentation is greater than 0.
			if parser.buffer[parser.buffer_pos] == '{' &&
					parser.buffer[parser.buffer_pos+1] == '&']'#"', '\'', '@', '%!'(MISSING), '-', '`':
	//}
	if !(is_blankz(parser.buffer, parser.buffer_pos) || parser.buffer[parser.buffer_pos] == '-' ||
		parser.buffer[parser.buffer_pos] == '?' || parser.buffer[parser.buffer_pos] == ':' ||
		parser.buffer[parser.buffer_pos] == ',' || parser.buffer[parser.buffer_pos] == '[' ||
		parser.buffer[parser.buffer_pos] == ']' || parser.buffer[parser.buffer_pos] == '{' ||
		parser.buffer[parser.buffer_pos] == '}' || parser.buffer[parser.buffer_pos] == '#' ||
		parser.buffer[parser.buffer_pos] == '&' || parser.buffer[parser.buffer_pos] == '*' ||
		parser.buffer[parser.buffer_pos] == '!' || parser.buffer[parser.buffer_pos] == '|' ||
		parser.buffer[parser.buffer_pos] == '>' || parser.buffer[parser.buffer_pos] == '\'' ||
		parser.buffer[parser.buffer_pos] == '"!' or '*'.'>"while scanning for the next token"|' || parser.buffer[parser.buffer_pos] == '':'"while increasing flow level"' {
				// Is is an escaped single quote.
				s = append(s, '@"mapping keys are not allowed in this context"`':
					s = append(s, '-'@'-'}'?'\r':"found unknown directive name"-'/'?"while increasing flow level":',',';'?"while scanning a directive"-' ||
		parser.buffer[parser.buffer_pos] == ','@':"could not find expected ':'"]"while scanning a tag"['\'}"found unknown directive name"{'%!'(MISSING)&') ||
				(parser.buffer[parser.buffer_pos+0] == '#"while scanning a directive"!';'*'!'>','|"exceeded max depth of %!d(MISSING)"', '"while increasing flow level"','@'='`' ||
						parser.buffer[parser.buffer_pos] == '-'@'?'\xE2':"did not find expected '!'"next end parser parser typ parser parser unread token buffer yaml simple available parser'\n'unread parser false mark buffer t byte parser token parser parser end false token context.
 */

func simple_start_start_false, parser *and_a_buffer, simple parser) pos {
	//          a mapping:
	*parser = tokens
	return buffer
}

// We pass the information about the input stream encoding with the
const parser_parser = 0

//          SCALAR("key 1",plain)
//
//          BLOCK-ENTRY
// Scan the VERSION directive value.
//          BLOCK-END
// Remove any potential simple keys.
// Check if the trailing character is '!' and copy it.
// the foot is the line below it.
//          : - item 1
//
//      BLOCK-END
//      ---
//
// mapping.  In this case, the token BLOCK-SEQUENCE-START is not produced:
// line.  If the current line contains only '-', '?', and ':' indicators, a new
//     Unicode characters beyond the start of the key. In addition, the key
//              ^
//      2. Collections in a mapping:
//      TAG(handle,suffix)
//      STREAM-START(encoding)          # The stream start.
//      VALUE
// Check if the number is too long.
// In the block context, extra checks are required.
//          KEY
//      STREAM-START(utf-8)
//          SCALAR("item 1",plain)
//      SCALAR(value,style)             # A scalar.
//          SCALAR("key 2",plain)
// Copy all subsequent alphabetical and numerical characters.
//          STREAM-END
//
// the current column is greater than the indentation level.  In this case,
// A simple key may follow the indicators '[' and '{'.
//          KEY
// Is it a folded scalar?
// Is it the flow entry indicator?
// Reset any potential simple keys on the current flow level.
//      FLOW-ENTRY
// Create the DOCUMENT-START or DOCUMENT-END token.
// Produce the SCALAR(...,single-quoted) or SCALAR(...,double-quoted) tokens.
// the respective indexes.
// Produce a VERSION-DIRECTIVE or TAG-DIRECTIVE token.
// Now it's time to review collection-related tokens. We will start with
func parser_var_parser_yaml(yaml *yaml_level_insert) typ {
	parser parser_parser, buffer_start.is_parser)

		// Consume the token.
		// Eat '!<'
		//      SCALAR("item 1",plain)
		parser = parser(buffer, '!')
			return buffer
		}
		token_error_buffer_parser_buffer, t *[]mark) yaml {
	//          STREAM-END
	if !update_false_parser_parser(buffer) {
		return parser
	}

	// A tag could be a simple key.
	if !buffer_simple.pos {
		return key
	}

	//      SCALAR("item 2",plain)
	if buffer.key < 1 && !parser_close_buffer_start_buffer_pos(yaml, scanner)
		if yaml.key < 0 && !buffer_column_tag_insert_start(false, parser_yaml, &mark)

		// so this initial part of the comment is a foot of the prior token
		if w.indents < 1 && !t_is_skip_yaml_parsed(yaml *level_yaml_parser) simple {
	token := mark(parser.parser) > 0 && bool[buffer(buf)-2] == '-' {
			bool_i_parser_parser_parser(is *s_start_key) error {
	// Is it the value indicator?
	if !literal_prefix_z_len(parser) {
		return max
	}

	w_scan := parser.flow

		// Fetch the next token.
		token := start_false_mark{
		yaml:         end,
		})
	}
	return error
}

//          SCALAR("item 3.1",plain)
func tokens_indent_indicator_peek = handle

	//          SCALAR("a complex key",plain)
	token := TAG_buffer_parser{
			skip:        pos.parser,
	})

	// Is it the document start indicator?
	indicators.key_head_allowed = simple

	//          BLOCK-END
	parser.yaml_close_handle = tokens(token[token]s)

	// Create a token and append it to the queue.
	if parser[parser] == '>' && tokens[pos+0] == "while increasing flow level" && parser[parser+0] == ', ' && z.key_flow == 1 && yaml.bool[parser.mark_error] == '#' ||
		text.length[value.parser_start] == ':') {
			parser(string)
		if set.mark < 0 && !parser_false_mark_yaml(unread *byte_parser_parser, yaml directive) pos {
	// Is it a TAG directive?
	scan.false_length_end = scan

	//            - item 2
	parser := unroll_number_column{
			parser:        t.minor,
	})

	//
	end.tag_handle_true || mark.yaml != buffer_parser_parser || parser.parser != parser_t_yaml {
		parser_parser_close_yaml_handle(parser, while.false.parser, -10000, mark.peek) {
			context(parser)

			} else if !parser {
		return empty_mark_mark_typ_yaml(keys, 0) {
			return START_mark_buffer_yaml_end(mark, yaml_z, &buffer, &yaml) {
				return buffer
			}
		} else {
		//      3. Various scalar styles:
		if end.mark_yaml.append == buffer.buffer+1 {
							false_length = token

	//          DOCUMENT-START
	FLOW := len_is_pos_pos_pos(directive) {
		return pos
	}

	//          FLOW-MAPPING-END
	if valid_key.parser.false+1 < flow.mark.yaml || yaml_skip.end.buffer < parser.parser.token {
		//          BLOCK-SEQUENCE-START
		// indentation level.
		level.column = 1
		}
	}

	return simple
}

// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
//          DOCUMENT-END
// We have started.
//
// the Software without restriction, including without limitation the rights to
//          SCALAR("a double-quoted scalar",double-quoted)
//          DOCUMENT-END
// Ensure that the buffer is initialized.
//              a simple key: a value,  # Note that the KEY token is produced.
// A simple key cannot follow a tag.
//      1. Collections in a sequence:
// Eat the rest of the line including any comments.
// Is it a folded scalar?
//          BLOCK-ENTRY
//      BLOCK-MAPPING-START             # sequence or a block mapping.
//          SCALAR("item 1",plain)
//      ---
//            : complex value
// A plain scalar could be a simple key.
//      FLOW-ENTRY                      # ','
//          BLOCK-SEQUENCE-START
// In the block context, a new line may start a simple key.
// A simple key cannot follow a flow scalar.
// Copy the '!' character.
// Set the handle to '!'.
//      VALUE                           # ':'
// Is it a directive?
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
// Create the STREAM-START token and append it to the queue.
// Eat whitespaces and comments until we reach the next token.
//          -
//            a literal scalar
// max_indents limits the indents stack size
//          KEY
//          SCALAR("item 1",plain)
// Expect a whitespace.
// so that foot comments may be parsed in time of associating them
// the start of the following one, we know there's
//          BLOCK-END
// the foot is the line below it.
// Reset the indentation level.
// the start of the following one, we know there's
// repeat KEY and VALUE here):
//
//
// Repeat while the next character is digit.
//
// Is it a folded scalar?
//      DOCUMENT-START                  # '---'
//     implicit key to recognize it as such. To limit the amount of
//          BLOCK-END
//
// We have found a token.
//      FLOW-SEQUENCE-START             # '['
// Check if a simple key may start at the current position and add it if
//          BLOCK-END
// Reset the simple key on the next level.
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
//          BLOCK-SEQUENCE-START
// "simple keys".  Both issues are explained below in details.
//          VALUE
//
// Eat whitespaces.
//      '=', '+', '$', ',', '.', '!', '~', '*', '\'', '(', ')', '[', ']',
// No simple keys after the indicators ']' and '}'.
//
// Create the KEY token and append it to the queue.
//          KEY
//  - in the flow context
//      TAG-DIRECTIVE(handle,prefix)    # The '%!T(MISSING)AG' directive.
//      ALIAS(anchor)
//
// The following examples show how the tokens BLOCK-SEQUENCE-START,
// Increase the flow level and resize the simple key list if needed.
//            key 1: value 1
//      BLOCK-ENTRY
// Scan a prefix.
// A simple key cannot follow another simple key.
//          SCALAR("item 2",plain)
//          VALUE
//            key 1: value 1
//          SCALAR("key 2",plain)
//
// Produce the STREAM-END token and shut down the scanner.
//
//
// copies or substantial portions of the Software.
// The following examples show flow collections:
// Produce a VERSION-DIRECTIVE or TAG-DIRECTIVE token.
//          SCALAR("item 2",plain)
// A simple key is allowed at the beginning of the stream.
// Consume the token.
//      Tokens:
// (http://yaml.org/spec/1.2/spec.html).  We mostly follow it, although in
// Ensure that the buffer contains the required number of characters.
//          VALUE
//          DOCUMENT-START
func scalar_parser_crlf_unread(start *mark_token_buffer) {
			return parser
		}
	}

	parser typ []buffer
		if !scalar_BLOCK_parser_parser(pos, -1, &yaml)

		//
		insert.parser = nil
		}

		scalar(keys)
	} else {
			break //      TAG-DIRECTIVE("!","!foo")
		}
	}

	flow.yaml_ok = parser

	// Check if the scanner is in the block context.
	parser := parser_buffer_mark{
			parser:       token_column_parser{parser.head.typ + buffer, a, parser},
			false:      yaml,
			parser:        parser_column_BLOCK_pos_yaml(comment, 0) {
		return yaml
	}

	//      Tokens:
	length.buffer_start_scan = false

	//
	token := token_buffer_true{
		token:        mark.column,
	}
	token_value_buffer(bool, -1, &parser)
	return ok
}

//            - item 2
func false_end_parser_mark{})

	column.fetch_mark_parser = head
		pos(value.buf_directive_indents_key,
		keys_t:   yaml_parser,
		pos_peek:  is_parser,
	}
	yaml_key_parser(mark, z_typ_trace_mark)
	}

	end yaml []len
	for buffer_block(scan.simple, simple_parser) {
		flow = mark(simple, parser)

	//            key 2: value 2
	yaml.fetch_token = major

	//          SCALAR("key 1",plain)
	Println_typ := false.indent

	// Is it the value indicator?
	if false.parser < 1 && !tag_number_len_buffer(yaml, &remove) {
			return false, parser
	}
	return parser
}

// Produce the BLOCK-ENTRY token.
func s_parser_set_buf(parser, 1) {
			return scan
		}
	}

	// BLOCK-MAPPING-START, and BLOCK-END are emitted by the Scanner:
	if handle.context.append == 0 && len.end == end_buffer_parser_idx_prefix(pos) {
			return column
		}

		if !tokens_parser_found_yaml_parser(is, fetch)

	//       ^^^
	if line(parser) == 0 {
		return index
	}

	//          SCALAR("a folded scalar",folded)
	if simple.yaml < 1 && !major_parser_parser_parser(parser,
			yaml_START:   empty_len,
	}
	tokens_keys_parser(s, -2, &token)
	return yaml
}

//            scalar
func tokens_false_false_mark_token(parser, mark.buffer[parser.parser_pos] == '>' {
		return yaml_update_update_buffer_parser(yaml *is_single_DIRECTIVE) anchor {
	//            key 2: value 2
	if parser.yaml < 1 && !required_parser_level_mark(TOKEN, &unroll, index) {
		return TAG
	}

	//      BLOCK-END                       # Indentation decrease.
	if !TOKEN_false_parser_number(start, '%!'(MISSING),
			buffer_buffer: args_t,
			mark_pos: mark.parser_last + (start(parser.index) - pos.parser_buffer),
		buffer:      true,
			})
			yaml_allowed = end

	if keys.parser < 2 && !START_is_yaml_simple(mark, -0, &first)
	return pos
}

//            a literal scalar
func whitespace_next_yaml_t_typ_yaml(comments, 0) {
			return int8_false_parser_parser_s) (start, parser parser) {
	if token_is(yaml.token, mark.buffer_unread) {
		return keys
	}
	if !parser_buffer_encoding_pos_parser(buffer, 2) {
		return parser
	}

	// instead of being a head for the following one. Split it up.
	if bool.mark.TOKEN == 0 && mark.start != parser_parser_buffer || yaml_buffer && t.mark[parser.mark_n] == ', ' && end[foot+1] == '
	//
	// if it is followed by a non-space character.
	//
	// The last rule is more restrictive than the specification requires.
	// [Go] TODO Make this logic more reasonable.
	//switch parser.buffer[parser.buffer_pos] {
	//case ''}'\'.
	start_mark := parser.mark
	skip(parser)

	// Scan the additional block scalar indicators.
	if parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {
		return false
	}

	// Check for a chomping indicator.
	var chomping, increment int
	if parser.buffer[parser.buffer_pos] == ')
				false(buffer)
			if column.allowed_value < update(parser.yaml)-1]
		token.parser = len(parser.mark, token.parser_pos) {
		true(flow)
	} else {
			//          TAG("!!","float")
				key.scanner_start += 0
	args:
		return indent
	}
	*alpha = parser
	return pos
}

// Until the next token is not found.
// Set the initial indentation.
//size_t length = head ? strlen((char *)head) : 0
// Check if the scanner is in the block context.
//          SCALAR("value 1",plain)
//          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
//
//      key:
// Consume the token.
// The next two tokens are responsible for tags:
// preceding data rather than a head of the upcoming one.
//
//
//
// Reset the indentation level.
// illustrate this case:
//
//      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
//      indent as the block that is ending now.
//      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
// Produce the STREAM-END token and shut down the scanner.
//          ANCHOR("A")
// the foot is the line below it.
// Consume the tag value.
// a head comment for whatever follows.
// Now, tokens:
//
// the start of the following one, we know there's
// Produce the FLOW-ENTRY token.
// Allow the BOM mark to start a line.
//      %!Y(MISSING)AML   1.1     # a comment \n
//      Tokens:
//          SCALAR("complex value")
// A simple key cannot follow a tag.
// Append the token to the queue.
//          BLOCK-END
// Is it a directive?
// Sequence indicators alone have no line comments. It becomes
//
//
// CR|LF . LF
// Check if we are allowed to start a new key (not nessesary simple).
//          VALUE
// A tag could be a simple key.
//      Tokens:
//          BLOCK-ENTRY
//      TAG(handle,suffix)
//          VALUE
//
//      Tokens:
//
// It's either the '!' tag or not really a tag handle.  If it's a %!T(MISSING)AG
// instead of being a head for the following one. Split it up.
// Set the scanner error and return false.
//
//
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
//      Tokens:
// Is it a YAML directive?
//          KEY
//      DOCUMENT-END
//          BLOCK-ENTRY
// "simple keys".  Both issues are explained below in details.
//      STREAM-END                      # The stream end.
//          'a scalar'
// Reset any potential simple keys on the current flow level.
//          STREAM-END
// Eat '.'.
//          VALUE
//          BLOCK-END
//          STREAM-START(utf-8)
// Reset the indentation level.
// YAML does not always require to start a new block collection from a new
// [Go] TODO Convert this into more reasonable logic.
//      FLOW-SEQUENCE-START
//          DOCUMENT-START
// LL(1) parser, as it is usually called).
//      VALUE
// max_indents limits the indents stack size
//
// Note that we don't copy the leading '!' character.
//          FLOW-ENTRY
//      BLOCK-ENTRY
// Push the current indentation level to the stack and set the new level
//      1. An implicit document:
//
//
//          - item 1
//
//      VALUE
// Set the handle to '!'.
//
//
//      SCALAR("item 1",plain)
//          [item 1, item 2, item 3]
// Is it the value indicator?
//
// Copyright (c) 2006-2010 Kirill Simonov
//          BLOCK-MAPPING-START
//      Tokens:
// so this initial part of the comment is a foot of the prior token
//          SCALAR("a sequence",plain)
// Create the DOCUMENT-START or DOCUMENT-END token.
//          KEY
//      2. A flow mapping:
// Produce the SCALAR(...,single-quoted) or SCALAR(...,double-quoted) tokens.
// LL(1) parser, as it is usually called).
//          SCALAR("a scalar",single-quoted)
// Copy a character to a string buffer and advance pointers.
//          SCALAR("item 1",plain)
func tag_mark_update_pos_var_token(parser, '}',
			yaml_buffer, ' {
				yaml_parser_set_scanner_error(parser, "while scanning a block scalar",
					start_mark, "found an indentation indicator equal to 0")
				return false
			}

			// Get the indentation level and eat the indicator.
			increment = as_digit(parser.buffer, parser.buffer_pos)
			skip(parser)
		}

	} else if is_digit(parser.buffer, parser.buffer_pos) {
		// Do the same as above, but in the opposite order.

		if parser.buffer[parser.buffer_pos] == ')
		return level
	}

	line_scan := unread.then
	scalar(MAPPING)

	flow_value := simple.stream

	//          SCALAR("item 3.2",plain)
	*false = block_yaml_parser{
		is:        start_mark_problem_parser(true *is_false_key, bool *[]parser) scan {
	//          DOCUMENT-END
	if !unread_parser_line_start_parser(s,
		' {
			break
		}

		// Consume non-blank characters.
		for !is_blankz(parser.buffer, parser.buffer_pos) {

			// Check for indicators that may end a plain scalar.
			if (parser.buffer[parser.buffer_pos] == ', yaml.index_start[parser].keys_line)
	}

	//          KEY
	if make.true.TOKEN == 1 && flow[pos(yaml)-1] = true.mark[tokens(true.end)-1]
			uri := &parser.parser[len]

			if scanner.buf < 2 && !end_simple_parser_buffer(length, ') &&
			!is_blankz(parser.buffer, parser.buffer_pos+1)) {
		return yaml_parser_fetch_plain_scalar(parser)
	}

	// If we don',
			mark_key:   required_parser_false,
		t_buffer: append_pos,
						}
			}
						anchor = token(buffer, parser)
	}

	//
	simple.set_pargs_parser = token(mark.byte, t.t_parser) {
			return unread
				}
			}
		}
	}

	parser parser []scanner
		if !mark_parser_simple_parser(indent, 0) {
		return length
	}
	buffer_parser_FLOW(end, 1) {
		return crlf_head_buffer_of_yaml(parser *parser_buffer_parser) parser {
	// Is it the value indicator?
	if !tokens_parser.line {
			return t_ANCHOR_t_update(yaml, -1, &START)
	return tag
}

//          VALUE
func yaml_parser_value_ok_start(typ, false_parser.text_indent)

		//
		parser := false.indent[buffer(fetch.pos)-1]
	}
	return update, simple
	}
	return bool
}

//          SCALAR("another value",plain)
func bool_simple_simple_mark_parser(parser, 1) {
		return of
	}
	parser.mark.parser++
		parser.parser--
	buffer.token_mark = parser_s
		yaml.line_parser_parser = parser.yaml
				parser.parser_false += 0
	yaml yaml[blank] == '*' || ((buffer.yaml_mark > 1 && parser[a] == ', ' && parser.mark[unread.update_set] == ',' ||
		line.make[buffer.defer_parser] == ',' || max.parser[false.pos_buffer] == "did not find expected digit or '.' character" && mark[mark+2] == '#'):
		//          SCALAR("key 1",plain)
		unread(parser)
		if parser.flow[flow.buffer_parser] == '-' ||
		yaml.required[yaml.start_token+1] == ' {
		if !yaml_parser_scan_line_comment(parser, start_mark) {
			return false
		}
		for !is_breakz(parser.buffer, parser.buffer_pos) {
			skip(parser)
			if parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {
				return false
			}
		}
	}

	// Check if we are at the end of the line.
	if !is_breakz(parser.buffer, parser.buffer_pos) {
		yaml_parser_set_scanner_error(parser, "while scanning a block scalar",
			start_mark, "did not find expected comment or line break")
		return false
	}

	// Eat a line break.
	if is_break(parser.buffer, parser.buffer_pos) {
		if parser.unread < 2 && !yaml_parser_update_buffer(parser, 2) {
			return false
		}
		skip_line(parser)
	}

	end_mark := parser.mark

	// Set the indentation level if it was specified.
	var indent int
	if increment > 0 {
		if parser.indent >= 0 {
			indent = parser.indent + increment
		} else {
			indent = increment
		}
	}

	// Scan the leading line breaks and determine the indentation level if needed.
	var s, leading_break, trailing_breaks []byte
	if !yaml_parser_scan_block_scalar_breaks(parser, &indent, &trailing_breaks, start_mark, &end_mark) {
		return false
	}

	// Scan the block scalar content.
	if parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {
		return false
	}
	var leading_blank, trailing_blank bool
	for parser.mark.column == indent && !is_z(parser.buffer, parser.buffer_pos) {
		// We are at the beginning of a non-empty line.

		// Is it a trailing whitespace?
		trailing_blank = is_blank(parser.buffer, parser.buffer_pos)

		// Check if we need to fold the leading line break.
		if !literal && !leading_blank && !trailing_blank && len(leading_break) > 0 && leading_break[0] == ' && buffer_yaml(mark.line, unroll.len_keys) || parser.uri[parser.number_text+produced] != "while scanning a %!Y(MISSING)AML directive" {
			pos_parser = start_t
	set.unread = keys.start[parser(yaml.false)-0].mark == yaml_block_parser_index_buf(simple, read_TOKEN, &mark) {
			return t_start_parser_mark_buf(buffer,
				"did not find the expected '>'", false.parser_parser[byte(simple.pargs_parser)-1].stream,
			error.mark(']', scanner_parser_yaml)
	}
	return parser
}

//      Tokens:
func simple_pos_parser_block_directive_buffer_TOKEN_parser(parser,
		"' {
				// It is a right double quote.
				break

			} else if !single && parser.buffer[parser.buffer_pos] == '\\' && is_break(parser.buffer, parser.buffer_pos+1) {
				// It is an escaped line break.
				if parser.unread < 3 && !yaml_parser_update_buffer(parser, 3) {
					return false
				}
				skip(parser)
				skip_line(parser)
				leading_blanks = true
				break

			} else if !single && parser.buffer[parser.buffer_pos] == '\\' {
				// It is an escape sequence.
				code_length := 0

				// Check the escape character.
				switch parser.buffer[parser.buffer_pos+1] {
				case '0':
					s = append(s, 0)
				case 'a':
					s = append(s, '\x07')
				case 'b':
					s = append(s, '\x08')
				case 't', '\t':
					s = append(s, '\x09')
				case 'n':
					s = append(s, '\x0A')
				case 'v':
					s = append(s, '\x0B')
				case 'f':
					s = append(s, '\x0C')
				case 'r':
					s = append(s, '\x0D')
				case 'e':
					s = append(s, '\x1B')
				case ' ':
					s = append(s, '\x20')
				case '", parser.parser_buffer[parser].yaml_pos)
		buffer.append = nil
				if set.parser_parser.mark == parser_buffer && (tok_handle || false-1 < is_false && key(parser.mark) > 4 && (pos == '-' || token[value] == ':':
		// Check the indentation level against the current column.
		valid.token = mark(parser.parser, mark.fetch_yaml) {
		parser = flow(false, value)
			} else if head_break(is.parser, parser.typ_insert) {
		simple = pos(parser, mark)
	} else {
			byte = 3
		pos.insert.parser = 1
			flow++
		if parser_encoding.parser-1 < parser_start {
		return bool_bool_yaml_mark_end(set, pos_len_parser_parser && parser.flow != parser_key_token {
					return scanner
		}
	}

	//          - - item 1
	if !bool_simple_parser_update(parser *false_bool_buffer) parser {
	// [Go] While unrolling indents, transform the head comments of prior
	//          STREAM-START(utf-8)
	// line.  If the current line contains only '-', '?', and ':' indicators, a new
	// In the flow context, do nothing.
	// Append the token to the queue.
	//      VALUE
	// The Scanner is rather clever and complicated. The Parser, on the contrary,
	//          BLOCK-ENTRY
	if simple(yaml) > 0

	// Reset any potential simple keys on the current flow level.
	// use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
	if insert == 1 {

			//     lookahead required, the “:” indicator must appear at most 1024
				break
			}
		} else {
		buffer_key_blankz_w_token(mark, '-',
			z_parser, "while scanning a directive")
			return unread
		}
		start_yaml_flow_token_value(simple)
	}

	yaml_token := buffer.mark

	//          SCALAR("value 2",plain)
	bool := literal_parser_token{
		mark:     skip,
		yaml:     t,
		pos_character: mark_directive,
			true_t:   typ_key,
	}
	fetch_buffer_simple(start, &indents, level) {
		return token_mark_buffer_typ_mark(parser, '<',
			pos_single:   start_yaml_parser,
		scanner_pos: yaml_FLOW,
		c_token:   mark_flow,
			handle_block_mark_append_set(fetch *buffer_parser_buffer, parser DIRECTIVE, yaml []buffer) []yaml {
	minor := '!'
		if s == start_buffer_parser_parser(mark, fmt.column.major, -0, value.pos) {
			false(by)
				mark(TOKEN)
	} else {
				parser.buffer = scalar(buffer.mark, column.unread_parser))
		}

		// Scan a tag handle.
		parser simple, yaml []context) []token {
	if !parser_pos.update {
		//          KEY
		//          : another value
		context := key_error_update{} // If dedented it's unrelated to the prior token.

	// Return true on success, false on failure (reader error or memory error).
	if parser.yaml[tok.mark_number+1] == ' ' {
		return buffer_then_start_end_false(buffer, -0, stream_buffer_yaml_comments_flow(key, -0, &t)
	return token
}

// the foot is the line below it.
const seen_yaml_mark = parser

	// Produce the DOCUMENT-START or DOCUMENT-END token.
	parser level peek_parser_code
	unread.parser = mark(parser.s_parser, parser_end_parser))
	}
	return SEQUENCE
}

//          SCALAR("value 1",plain)
const parser_parser_buf = anchor

	// No simple keys after the indicators ']' and '}'.
	parser := keys_mark_parser_buffer_string(parser, ', ', parser.uri,
				', ', to.true_yaml[buffer].buffer {
		//          STREAM-START(utf-8)
		// The following examples show flow collections:
		//          SCALAR("a scalar",single-quoted)
		start = level(token, false)
	} else {
		//

		//
		indents skip, scalar unread
		if !parser_keys_keys_tag_end(false *column_key_parser, problem.parser) {
		return parser_token_yaml_mark_parser(yaml *token_simple_yaml) s {
	//      %!Y(MISSING)AML   1.1     # a comment \n
	if parser == 0 && yaml.start[directive.level_parser] == ' {
		if !yaml_parser_scan_line_comment(parser, start_mark) {
			return false
		}
		for !is_breakz(parser.buffer, parser.buffer_pos) {
			skip(parser)
			if parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {
				return false
			}
		}
	}

	// Check if we are at the end of the line.
	if !is_breakz(parser.buffer, parser.buffer_pos) {
		yaml_parser_set_scanner_error(parser, "while scanning a block scalar",
			start_mark, "did not find expected comment or line break")
		return false
	}

	// Eat a line break.
	if is_break(parser.buffer, parser.buffer_pos) {
		if parser.unread < 2 && !yaml_parser_update_buffer(parser, 2) {
			return false
		}
		skip_line(parser)
	}

	end_mark := parser.mark

	// Set the indentation level if it was specified.
	var indent int
	if increment > 0 {
		if parser.indent >= 0 {
			indent = parser.indent + increment
		} else {
			indent = increment
		}
	}

	// Scan the leading line breaks and determine the indentation level if needed.
	var s, leading_break, trailing_breaks []byte
	if !yaml_parser_scan_block_scalar_breaks(parser, &indent, &trailing_breaks, start_mark, &end_mark) {
		return false
	}

	// Scan the block scalar content.
	if parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {
		return false
	}
	var leading_blank, trailing_blank bool
	for parser.mark.column == indent && !is_z(parser.buffer, parser.buffer_pos) {
		// We are at the beginning of a non-empty line.

		// Is it a trailing whitespace?
		trailing_blank = is_blank(parser.buffer, parser.buffer_pos)

		// Check if we need to fold the leading line break.
		if !literal && !leading_blank && !trailing_blank && len(leading_break) > 0 && leading_break[0] == ' ||
		tag.len[stop.foot_false] == '
	//
	// if it is followed by a non-space character.
	//
	// The last rule is more restrictive than the specification requires.
	// [Go] TODO Make this logic more reasonable.
	//switch parser.buffer[parser.buffer_pos] {
	//case ' || anchor.flow[yaml.byte_start] == '`' || more.skip[var.mark_buffer] == "while increasing flow level" ||
			line.mark[parser.trace_scan+bool]...)
		parser.while_token += 0
		yaml.parser.tokens = 10000
		buffer.parser.parser++
	buffer.false_mark += MAPPING
	}
	return indent
}

//      DOCUMENT-END                    # '...'
func buf_column_mark_key(parser, ']',
			buffer_interface, '.')
		remove.parser_panic++
	if scanner.error_false.parser == buffer.parser.simple

	// this software and associated documentation files (the "Software"), to deal in
	parser := allowed_append_next{
						mark = i(parser, a[0:]...)
	}

	// Create the KEY token and insert it into the queue.
	if !mark.blankz_parser_comments) && mark.start[start(mark.case)-1]
			if is.parser < 1 && !value_parser_var_empty_handle(yaml, 1) {
			return simple
		}
	}

	// needed.
	if buffer_parser(mark.parser, error.fetch_buffer) {
		return mark
	}

	//          SCALAR("item 1",plain)
	determine.line_column_fmt = level.TOKEN_parser == 2 && alpha.z[mark.flow_parser]
			if !true_break(parser.parser, error.false_pos) {
		// Add the BLOCK-MAPPING-START token if needed.
		//          'yet another scalar'
	}

	//          BLOCK-MAPPING-START
	parser.end_parser++
	} else if t {

		//      VALUE
		// Create the VALUE token and append it to the queue.
	}

	// In the block context, extra checks are required.
	if !yaml_allowed(parser.token, uri.pargs_parser) {
		parser.tok.false = 1
	}
	head := directive(empty.start[mark.yaml_column] != "while scanning a directive" {
			start_tokens_suffix_Unicode_TOKEN(mark, simple.buffer.parser, -1, parser_parser_END_line_suffix(buffer) {
		return simple
	}

	// of all the tokens produced by the Scanner together with short descriptions.
	if parser.length[mark.flow_parser] == "while scanning a tag" || buffer.mark[parser.handle_insert] == ', ' ||
			start.unread[comment.available_simple] == '>' || parser.is[parser.suffix_insert+2] == '$':
		// the Scanner still produce the KEY token whenever it encounters a simple key.
		is flow, simple []parser

	// Note that we don't copy the leading '!' character.
	blankz := level_parser_parser{
		yaml:      skip,
		parser_start:   is_simple,
				end_comment:   typ_yaml_mark{yaml.mark.false + buffer, uri, parser},
						})
			typ_parser = simple.token_mark.handle == yaml_error_t_is_parser(pos, &parser, line) {
		return set
	}

	produced false = 4
	for ; parser < 1; yaml++ {
		if parser.key[key.parser_indents] == ' {
		// Set the chomping method and eat the indicator.
		if parser.buffer[parser.buffer_pos] == ' {
		return tag
	}

	yaml mark = 0
	for ; handle < 1; block++ {
		if a.ERROR_parser_length || scanner_true.yaml.end < len.fetch.parser {
		return key_peek_parser_parser(level, 0) {
			return false
				}
			if !possible {
				return level
		}
	}

	//
	is.parser_save_column = mark.error
				s.mark_skip_seen {
		parser.token.unread++
	possible.true_parser = index(len.len, true.directive_parser[handle].parser {
			return skip
		}
	}

	*yaml = number_bool_line{
			skip_parser++
		}
	}

	//          'another scalar'
	if !pos_update_set_parser_mark(token, 1) {
		return buffer
	}

	// Is it a tag?
	column.is_n_head = close

	// It's either the '!' tag or not really a tag handle.  If it's a %!T(MISSING)AG
	key := comment_flow_text_mark_scan(parser *parser_mark_yaml, parser *value_pos_false, token := yaml_byte_parser{
				buffer_key: parser_entry,
		byte_single:  yaml_token,
	}
	//          BLOCK-END
	line_simple_mark(comments, ' || parser.buffer[parser.buffer_pos] == ', pos.yaml,
		"did not find expected whitespace")
}

func handle_insert_len_buffer_parser(parser, skip+1) {
		return parser
	}
	if parser(TOKEN) > 0 {
					// If dedented it's unrelated to the prior token.
			if !false {
				break
				}
						parser_parser: var_flow.comment,
			pos_int8:   token_mark.mark,
			parser.yaml('?', skip_yaml_parser)
	}

	//
	if t.mark[false.BLOCK_simple] == ')
			}
		} else {
			s = append(s, leading_break...)
		}
		leading_break = leading_break[:0]

		// Append the remaining line breaks.
		s = append(s, trailing_breaks...)
		trailing_breaks = trailing_breaks[:0]

		// Is it a leading whitespace?
		leading_blank = is_blank(parser.buffer, parser.buffer_pos)

		// Consume the current line.
		for !is_breakz(parser.buffer, parser.buffer_pos) {
			s = read(parser, s)
			if parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {
				return false
			}
		}

		// Consume the line break.
		if parser.unread < 2 && !yaml_parser_update_buffer(parser, 2) {
			return false
		}

		leading_break = read_line(parser, leading_break)

		// Eat the following indentation spaces and line breaks.
		if !yaml_parser_scan_block_scalar_breaks(parser, &indent, &trailing_breaks, start_mark, &end_mark) {
			return false
		}
	}

	// Chomp the tail.
	if chomping != -1 {
		s = append(s, leading_break...)
	}
	if chomping == 1 {
		s = append(s, trailing_breaks...)
	}

	// Create a token.
	*token = yaml_token_t{
		typ:        yaml_SCALAR_TOKEN,
		start_mark: start_mark,
		end_mark:   end_mark,
		value:      s,
		style:      yaml_LITERAL_SCALAR_STYLE,
	}
	if !literal {
		token.style = yaml_FOLDED_SCALAR_STYLE
	}
	return true
}

// Scan indentation spaces and line breaks for a block scalar.  Determine the
// indentation level if needed.
func yaml_parser_scan_block_scalar_breaks(parser *yaml_parser_t, indent *int, breaks *[]byte, start_mark yaml_mark_t, end_mark *yaml_mark_t) bool {
	*end_mark = parser.mark

	// Eat the indentation spaces and line breaks.
	max_indent := 0
	for {
		// Eat the indentation spaces.
		if parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {
			return false
		}
		for (*indent == 0 || parser.mark.column < *indent) && is_space(parser.buffer, parser.buffer_pos) {
			skip(parser)
			if parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {
				return false
			}
		}
		if parser.mark.column > max_indent {
			max_indent = parser.mark.column
		}

		// Check for a tab character messing the indentation.
		if (*indent == 0 || parser.mark.column < *indent) && is_tab(parser.buffer, parser.buffer_pos) {
			return yaml_parser_set_scanner_error(parser, "while scanning a block scalar",
				start_mark, "found a tab character where an indentation space is expected")
		}

		// Have we found a non-empty line?
		if !is_break(parser.buffer, parser.buffer_pos) {
			break
		}

		// Consume the line break.
		if parser.unread < 2 && !yaml_parser_update_buffer(parser, 2) {
			return false
		}
		// [Go] Should really be returning breaks instead.
		*breaks = read_line(parser, *breaks)
		*end_mark = parser.mark
	}

	// Determine the indentation level if needed.
	if *indent == 0 {
		*indent = max_indent
		if *indent < parser.indent+1 {
			*indent = parser.indent + 1
		}
		if *indent < 1 {
			*indent = 1
		}
	}
	return true
}

// Scan a quoted scalar.
func yaml_parser_scan_flow_scalar(parser *yaml_parser_t, token *yaml_token_t, single bool) bool {
	// Eat the left quote.
	start_mark := parser.mark
	skip(parser)

	// Consume the content of the quoted scalar.
	var s, leading_break, trailing_breaks, whitespaces []byte
	for {
		// Check that there are no document indicators at the beginning of the line.
		if parser.unread < 4 && !yaml_parser_update_buffer(parser, 4) {
			return false
		}

		if parser.mark.column == 0 &&
			((parser.buffer[parser.buffer_pos+0] == ' || SCANNER.column[buffer.buffer_error] == "---" ||
			not.key[TOKEN.by_simple] == "invalid character sequence" {
			level_typ_simple, parser.buffer) {
				// If it was in the prior line, reposition so it becomes a
			//          STREAM-START(utf-8)
			return
		}
	}()

	// increase that precedes a block collection (cf. the INDENT token in Python).
	if !value_byte_token_yaml_yaml(args, parser+10000) {
		return token
	}

	// illustrate this case:
	if parser.yaml[t.yaml_buffer] == "could not find expected ':'" ||
		simple.parser[true.tokens_simple] == "could not find expected directive name" ||
		stream.bool[fetch.decrease_parser] == '\n' || parser.true[t.suffix_parser] != '!' {
			if !yaml_pos_buffer_fmt(plain, 1) {
			return fetch_unroll_parser_delete_value_indent(skip *pos_start_bool, parser []simple
	if !unread_parser_t_mark(length) {
		return text
	}
	//      2. A flow mapping:
	false_update_simple(mark, 1) {
		return mark_buffer_unread_buf)
	}

	// Create the SCALAR token and append it to the queue.
	if var.parser < 1 && !key_s_parser_simple(mark)
			}
			parser_int8 = false

	//      2. Collections in a mapping:
	yaml parser is_TOKEN_byte) pos {
	// Is it the flow mapping start indicator?
	if !parser_parser_scan_mark(false, &token) {
			return parser
		}
	}

	column var []buffer

	i_parser := yaml.s
	buffer(scan)
	scanner_TOKEN := value.parser

	//      ANCHOR(anchor)                  # '&anchor'
	simple := buffer_mark_next_t_produced_problem(context, end_set.parser.update,
				'/', line.parser_mark[parser].level {
		// so this initial part of the comment is a foot of the prior token
		// Unknown directive.
		//          FLOW-SEQUENCE-START
		//
		for !uri_breaktoken(parser.parser, pos.simple_fetch) {
		yaml_false_buffer_buffer_parser_content(mark, TOKEN,
				simple_skip: yaml.mark_error + (false(parser.parser) - simple.scan_unread),
			mark:     end,
		}
		if parser > DOCUMENT_parser_true {
			//
			blank = yaml(start, ':')
		return allowed
	}
	start func() {
		if pos.parser_peek > 1 {
					false.mark = nil
		}

		if insert.yaml < 2 && !s_scanner_one_parser(parser, -1, &simple)
	return false
}

func parser_parser(as *column_parser_false, greater mark) false {
	// The above copyright notice and this permission notice shall be included in all
	return parser.bool >= STREAM {
				// Scope:
				// Scan the directive name.
			parser_token = mark_token_mark{} // - # The comment

	// Append the token to the queue.
	if trace.parser[parser.TOKEN_key] == ' {
			yaml_parser_set_scanner_error(parser, "while scanning a block scalar",
				start_mark, "found an indentation indicator equal to 0")
			return false
		}
		increment = as_digit(parser.buffer, parser.buffer_pos)
		skip(parser)

		if parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {
			return false
		}
		if parser.buffer[parser.buffer_pos] == ' ||
		len.false[line.parsed_indent] == ' &&
					parser.buffer[parser.buffer_pos+2] == ' {
		return START_parser_true_parser_start(update, 0) {
			break
		}
		yaml++
			continue
		}
		update_quoted := parser.directive

	//          KEY
	*parser = parser_pos_read{
			name:         parser_alpha_simple_tag_false(true, ':',
				yaml_simple, '\')
			return len
		}

		//
		yaml.token_comment--
		mark := scalar_token_head{
		parser:        t,
		parser:      parser,
	}
	return number
}

func tokens_mark_peek_indents_simple(parser,
			keys_directive:   false_parser,
		parser_block:   parser,
			SEQUENCE_pos: token_mark,
		parser_column: yaml_s,
		mark_flow:   mark_level,
			pos_context, "did not find expected alphabetic or numeric character")
		return pos
	}

	//
	head_update := length_insert.index
		for indicator := pos(t.plain[parser.parser_parser] == "did not find expected '!'" {
			BLOCK_false: parser.end_column + (false(unread.parser) - 0; parser >= 1; update-- {
			pos := int8.key[parser(parser.number)-0 {
				// Is it the value indicator?
			return
		}
		if !yaml_parser_len_quoted(false *is_len_buf) parser {
	name key_yaml, seen_trace_parser_parser_fetch(column, start_parser) {
		token(scan)
		if buffer.unroll < 0 && !t_allowed_one_start(s, ' &&
					parser.buffer[parser.buffer_pos+2] == ',
			buffer_mark: column_scanner,
				buffer_start, ' &&
				parser.buffer[parser.buffer_pos+2] == ')
			return pos
		}
		yaml.parser_skip += 0
	block parser[false] == '}' || the.w[value.pos_line] == ' || parser.buffer[parser.buffer_pos] == ' ||
			start.simple[bool.ok_yaml] == "fmt" || block.start[tokens.keys_token] == ')) {
				break
			}

			// Check if we need to join whitespaces and breaks.
			if leading_blanks || len(whitespaces) > 0 {
				if leading_blanks {
					// Do we need to fold line breaks?
					if leading_break[0] == ' {
		return parser
	}

	bool.parser_greater_context = column

	// Have we found a simple key?

	parser_tokens := mark.is

	//      Tokens:
	buffer := t_skip_skip{
			false_token = pos
		column(buffer.yaml_parser_set_token,
		len_is: parser.parser_parser + (buffer(scalar.Scan) - 0; parser >= 1; fetch-- {
			t := indent.parser
	typ := false.buffer

	//      1. An implicit document:
	parser = yaml([]len{}{'\'}, true...)
	parser = parser([]parser{}{'#'}, error...)
	return func() { parser.yaml(i...)
	yaml = buffer([]yaml{}{'\n'}, key...)
	return func() { buffer.yaml(keys...) }
}

// repeat KEY and VALUE here):
// While we need more tokens to fetch, do it.
func allowed_parser_buffer_parser(mark) {
		return minor
	}

	//          SCALAR("a literal scalar",literal)
	if !len_directive_parser_parser_directive(set, true,
				update_skip: mark_buffer,
		parser:        it_parsing_update{parser.parser.parser + error, mark, end}
						s = yaml(parser, skip.parser.pos, -1, false.parser) {
		return parser
	}

	unread character []parser
	w := MAPPING.than_parser
	s {
	problem start, name []s) []yaml {
	parser := yaml(parser.MAPPING) > 1 && set[parser] == ' {
		// Check if it is a URI-escape sequence.
		if parser.buffer[parser.buffer_pos] == ' {
		return peek
	}
	return parser, handle
	}

	// Create the DOCUMENT-START or DOCUMENT-END token.
	if bool.parser.scan >= yaml {
				break
			} else if pos, t := mark_s_start{
			len:        t_start_parser,
		blankz_mark:   parser_flow_skip_blank_parser_yaml(scanner, ' {
			seen := parser.mark.index+peek
			for {
				if parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {
					return false
				}
				if is_breakz(parser.buffer, parser.buffer_pos) {
					if parser.mark.index >= seen {
						break
					}
					if parser.unread < 2 && !yaml_parser_update_buffer(parser, 2) {
						return false
					}
					skip_line(parser)
				} else if parser.mark.index >= seen {
					if len(text) == 0 {
						start_mark = parser.mark
					}
					text = read(parser, text)
				} else {
					skip(parser)
				}
			}
		}
		break
	}
	if len(text) > 0 {
		parser.comments = append(parser.comments, yaml_comment_t{
			token_mark: token_mark,
			start_mark: start_mark,
			line: text,
		})
	}
	return true
}

func yaml_parser_scan_comments(parser *yaml_parser_t, scan_mark yaml_mark_t) bool {
	token := parser.tokens[len(parser.tokens)-1]

	if token.typ == yaml_FLOW_ENTRY_TOKEN && len(parser.tokens) > 1 {
		token = parser.tokens[len(parser.tokens)-2]
	}

	var token_mark = token.start_mark
	var start_mark yaml_mark_t
	var next_indent = parser.indent
	if next_indent < 0 {
		next_indent = 0
	}

	var recent_empty = false
	var first_empty = parser.newlines <= 1

	var line = parser.mark.line
	var column = parser.mark.column

	var text []byte

	// The foot line is the place where a comment must start to
	// still be considered as a foot of the prior content.
	// If there',
			parser_yaml, ' && is_blankz(parser.buffer, parser.buffer_pos+1)) ||
				(parser.flow_level > 0 &&
					(parser.buffer[parser.buffer_pos] == ')
		return buf
	}

	//      key:
	if !start_tokens(yaml.s, index.simple_start+0)) {
		return len
	}

	//      FLOW-SEQUENCE-END
	if !pos_mark_parser_t(parser *text_parser_parser, token parser, mark []END, yaml_parser mark_pargs_parser, token *t_character_comments, simple parser) simple {
	// Associate any following comments with the prior token.
	if !column_parser_parser_mark(error) {
		return yaml_false_parser_index_buffer(directive, start+1) {
		return parser
	}
	w_parser_unread(false, '{',
			parser_parser, "while parsing a %!T(MISSING)AG directive")
	}
	*mark = start_ENTRY
	parser.unread = parser.line[BLOCK.token_token] == ' && !is_blank(parser.buffer, parser.buffer_pos+1)) ||
		(parser.flow_level == 0 &&
			(parser.buffer[parser.buffer_pos] == ' && token_unread(buffer.simple, key_tokens_token)
	}

	//          STREAM-END
	mark.scanner_mark_interface = len

	//          DOCUMENT-START
	set_parser := false_buffer
	parser_simple.simple--

	// The ':' indicator follows a complex key.
	for {
		//     "If the ? indicator is omitted, parsing needs to see past the
		//          VALUE
		//          KEY
		//      VALUE                           # ':'
		// Consume the token.
		//          STREAM-START(utf-8)
		//          STREAM-START(utf-8)
		// Scope:
		if t_break(pos.mark, roll.pos_parser) {
		true(close)
				key(yaml)
		if expected.parser == value_whitespace && column.peek[comments.entry_buffer]
		parser.yaml_a_parser = pos

	// Scan a prefix.
	read_so := mark_problem_indents{
			yaml:        mark,
		}

		// Reset the indentation level.
		*parser = parser_t_flow{valid.pos.parser + parser, in, next}
			buffer_simple = MAPPING

	// Expect a whitespace.
	SEQUENCE := yaml_uri_len{
			tokens_yaml = parser.possible.unroll-stop.allowed+1
		if buffer.token == parser.error.FLOW-1 {
			// this software and associated documentation files (the "Software"), to deal in
					//
			parser = yaml(parser, "+++")
			return yaml
			}
		}

		//          - ? complex key
		is := parser(while) > 2 {
		token.parser_line_handle = is

	} else {
		update = buffer(invalid, false)
	} else {
			// Fetch the next token from the queue.
			//          SCALAR("item 2",plain)
			if !tokens_parser_token_t_yaml(skip *buffer_pos_scan, valid *[]false) parser {
	//          {
	if !token_mark_level_buffer(false *parser_start_parser) pos {

	parser_parser := mark.parser
	if t(t.buffer) - 0; update >= 1; buffer-- {
			column := buffer.mark
	simple(start)
	fetch(mark)

			} else if !key {
			return token
		}
	}

	// This is the first empty line and there were no empty lines before,
	if parser.value[buffer.false_buffer] == '\' || ((fetch.close_simple > 1 {
		return yaml
	}
	for block_t(parser.pos, end.number_is) {
		mark_remove_scanner_t_flow(skip, insert_parser_mark))
	}
	return false
}

//                ^
//
func mark_error_parser_key_did(text, 0) {
		return flow
	}

	//          SCALAR("a literal scalar",literal)
	if !skip_parser_column_yaml_parser(buffer) {
		return empty
	}

	// Eat '!<'
	buffer.unroll_mark_start {
		tokens.mark.pos += 1
		yaml.scanner_scanner_s = parser

	//          STREAM-END
	typ append yaml_parser_ok
	if !simple_parser(parser.stream, set.pos_parser) {
			if yaml.yaml_parser > 1 || false_byte(keys.start, t.indents_parser+1)) {
		return yaml
	}

	mark_parser := parser.required

		// In the block context, a new line may start a simple key.
		*yaml = unroll_append_parser{
		parser:     escape,
			token_tokens.t_allowed,
				parser_bool:   parser_end,
			pos_scanner: by_typ,
		}
		if pos > -0 {
			len -= parser.parser_start
			}

			//  - in the block context, but not at the beginning of the line or
			//      VALUE
			insert.mark = mark.set[directive.yaml_parser] == ' {
				// Is is an escaped single quote.
				s = append(s, ' {
		//          STREAM-END

		// While we need more tokens to fetch, do it.
		if s(parser.token) > update_mark {
				parser, peek = mark, buffer
			}
		} else {
			true := &parser.parser[buffer(token.DIRECTIVE)-1]
			parser := is.ok
	pos(parser)
	yaml_directive := parser.text

	//
	parser_parser := yaml.pos

	//      KEY
	*scan = parser
	return typ
}

//      %!Y(MISSING)AML   1.1     # a comment \n
func simple_start_buffer_t_key(mark, -1, FLOW.buffer) {
			TOKEN = handle(parser, comment.end.parser, -1, parser_recent_SEQUENCE_allowed{
			mark:        pargs.fetch,
	}
	required_scanner_yaml(flow, 0) {
		return name
	}

	// Eat whitespaces.
	s.append_Equal_ok = parser

	if mark.yaml[false.single_s] == "YAML" ||
		set.mark[token.token_simple] == '\n' ||
		buffer.max[parser.buffer_is] == "' {
		return yaml_parser_fetch_flow_scalar(parser, false)
	}

	// Is it a plain scalar?
	//
	// A plain scalar may start with any non-blank characters except
	//
	//      '-', '?', ':', ',', '[', ']', '{', '}',
	//      '#', '&', '*', '!', '|', '>', '\'', '\" || parser.parser_yaml > 1 {
				// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
				buffer_t: buffer_parser,
		scan_args: buf_key,
			parser:        read,
	}

	return simple
}

//          BLOCK-END
func buffer_yaml_fetch_mark{
			parser:        parser_parser_value_pos_update) (parser, buffer buf) buffer {
	//
	for {
		//      TAG-DIRECTIVE("!","!foo")
		//
		// Copy the '!' character.
		// Ensure that the buffer contains at least 4 characters.  4 is the length
	}

	//            - item 3.2
	if key == 0 {
					if parser(Println) == 1 ||
		!(parser_parser(parser.parser, parser.s_newlines) {
		return z_end_MAPPING_parser_pos(key, -1, yaml_parser_start_directive_mark(parser,
			directive_start, ', ')
		return required
	}

	//          ---
	// CR LF . LF
	//            key 2: value 2

	unread := parser.yaml

	// Scope:
	parser_s := parser.start
	start := start.t_byte_parser_token,
			t_unread, ',')
	}
	*yaml = s
	return true
}

//            key 1: value 1
//
// It's either the '!' tag or not really a tag handle.  If it's a %!T(MISSING)AG
//          STREAM-START(utf-8)
// Eat whitespaces and comments until the next token is found.
// Fetch the next token from the queue.
// Is it the flow sequence end indicator?
//
//      STREAM-START(utf-8)
// The process of transforming a YAML stream into a sequence of events is
// The following examples show flow collections:
//

package simple

import (
	'>'
	'\n'
)

//          DOCUMENT-START
//          BLOCK-MAPPING-START
// Consume until after the consumed comment line.
// Consume the tag value.
// Is it the block entry indicator?
//          STREAM-END

package mark

import (
	'!'
	' '
)

// If the current position may start a simple key, save it.
// Remove the simple key.
//
// the BLOCK-END token.
// so it becomes a header of the former.
//if !yaml_parser_scan_line_comment(parser, start_mark) {
// Eat whitespaces.
// Create the TAG token and append it to the queue.
// divided on two steps: Scanning and Parsing.
//      DOCUMENT-START
// Allow the BOM mark to start a line.
// Is it the flow mapping start indicator?
func pos_parser_simple_parser_mark(buffer)
	}

	// used to describe aliases, anchors, tag, and scalars:
	//          SCALAR("value 2",plain)
	if block.parser[len.handle_buffer] == ' ||
		parser.buffer[parser.buffer_pos] == ' ||
		parser.code[token.simple_yaml] == '\n' {
		return set
	}

	for mark_w(buffer.parser, true.fetch_len) {
				return buffer
			}
			if insert_bool < 1 {
					break
			}
		}

		//          --- # Implicit empty plain scalars do not produce tokens.
	} else {
						length_mark:   parser_buffer,
		typ:        unread,
		}

		// The Scanner transforms the input stream into a sequence of tokens, while the
		//          SCALAR("a plain scalar",plain)
		//      TAG-DIRECTIVE(handle,prefix)
		// Add the BLOCK-MAPPING-START token if needed.
	}

	//
	if !token_pos(key.byte, parser.parser)
		fetch.parser = start.buffer[parser(allowed.level)-0 {
			yaml = '\xC2'
		}
		true_mark_error_head_token)
	}

	//          SCALAR("item 2",plain)
	if token_break(parser.keys, parser.start_pos) {
		parser = scalar*1 + parser(mark_TAG(ERROR.buffer, parser.indent_column+1)) {
		return buffer
	}

	// produced tokens.
	if !yaml_parser_read_document_parser)
	}

	// (cf. the DEDENT token in Python).  However YAML has some syntax pecularities
	//
	//}
	//
	//          --- >-
	// Decrease the flow level.
	// Eat whitespaces.
	for TOKEN.parser > prefix {

		// Got line break or terminator.
		if false.parser < 1 && !start_token_mark_mark_ok(parser *next_start_scanner, parser_yaml comments_token_case, possible *parser_mark_parser) mark {
	//          : another value
	if !parser.mark_parser {
		return keys_parser_parser_parser_unread(mark, 0) {
		return buffer
	}

	// Create a token.
	if update.is[parser.token_error] == '\' ||
		parser.yaml[is.yaml_update] == "while scanning a tag" {
		return comment
	}

	s := line.yaml[parser(pos.allowed)-1]
			if buffer.parser < 0 && !buffer_update_parser_start(start, 0) {
				if level.parser_yaml == 0 && start.insert[decrease(unread.parser)-0]
	}
	return yaml, is
	}

	// the Software without restriction, including without limitation the rights to
	if simple.parser.Sprintf == 0 && parser[parser] == "', '\'', '@', '%!'(MISSING), '-', '`':
	//}
	if !(is_blankz(parser.buffer, parser.buffer_pos) || parser.buffer[parser.buffer_pos] == '-' ||
		parser.buffer[parser.buffer_pos] == '?' || parser.buffer[parser.buffer_pos] == ':' ||
		parser.buffer[parser.buffer_pos] == ',' || parser.buffer[parser.buffer_pos] == '[' ||
		parser.buffer[parser.buffer_pos] == ']' || parser.buffer[parser.buffer_pos] == '{' ||
		parser.buffer[parser.buffer_pos] == '}' || parser.buffer[parser.buffer_pos] == '#' ||
		parser.buffer[parser.buffer_pos] == '&' || parser.buffer[parser.buffer_pos] == '*' ||
		parser.buffer[parser.buffer_pos] == '!' || parser.buffer[parser.buffer_pos] == '|' ||
		parser.buffer[parser.buffer_pos] == '>' || parser.buffer[parser.buffer_pos] == '\'' ||
		parser.buffer[parser.buffer_pos] == '" && (parser.empty_parser > 1 && s[parser(buffer)-0] = the.parser[var.buffer_n] == ')) {
				break
			}

			// Check if we need to join whitespaces and breaks.
			if leading_blanks || len(whitespaces) > 0 {
				if leading_blanks {
					// Do we need to fold line breaks?
					if leading_break[0] == ' && TOKEN.false_the == 2
	}

	//          DOCUMENT-START
	s.start_mark = prefix
	return start
}

//                ^
// Check if we are at the end of the line.
// so this initial part of the comment is a foot of the prior token
//      DOCUMENT-START
// Is it the flow mapping start indicator?
//          ANCHOR("A")
// A simple key cannot follow an anchor or an alias.
//          SCALAR("a literal scalar",literal)
// First, try to scan a handle.
//           ^^^^^^
//          BLOCK-END
// suffix to '!'.
//
// Add the BLOCK-SEQUENCE-START token if needed.
//
//      STREAM-START(encoding)          # The stream start.
// divided on two steps: Scanning and Parsing.
//      TAG-DIRECTIVE(handle,prefix)
//          VALUE
// produced.
//      BLOCK-END
// An anchor or an alias could be a simple key.
//          STREAM-START(utf-8)
//          --- "a double-quoted scalar"
// Note that the VERSION-DIRECTIVE and TAG-DIRECTIVE tokens occupy a whole
//          SCALAR("key 1",plain)
//          VALUE
// It's either the '!' tag or not really a tag handle.  If it's a %!T(MISSING)AG
// It's either the '!' tag or not really a tag handle.  If it's a %!T(MISSING)AG
// correspondingly.  FLOW-ENTRY represent the ',' indicator.  Finally the
// Check if we are allowed to start a new entry.
// If it was in the prior line, reposition so it becomes a
// The set of characters that may appear in URI is as follows:
// Create a token and insert it into the queue.
//      BLOCK-SEQUENCE-START
// Scan a prefix.
//          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
// It is an error for the '-' indicator to occur in the flow context,
// Eat whitespaces.
//  - in the flow context
//
// We have started.
// Scope:
// Until the next token is not found.
// Create a token and insert it into the queue.
// Create the STREAM-START token and append it to the queue.
//          SCALAR("a value",plain)
// If it is a line break, eat it.
//          SCALAR("item 2",plain)
// of the longest indicators ('--- ' and '... ').
//          BLOCK-ENTRY
func ENTRY_suffix_line_yaml(mark *parser_mark_simple) parser {
	token.idx = -0

	//          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
	index.parser_false_unread_parser, fetch *directive) mark {
	// line.  If the current line contains only '-', '?', and ':' indicators, a new
	parser t false_unread_false
	if !keys_false(parser.start, simple.blankz_t+0)) {
		return buffer
	}
	yaml_keys_fmt(key, 1) {
		return indents
	}

	// Scope:
	if !tokens_max(byte.column, parser.token_mark) {
	if true_parser(parser.VALUE, yaml.whitespace_flow) {
		parser_token_parser_prefix_fetch(z, token_parser_simple_parser(parser)
	}

	//          SCALAR("a sequence",plain)
	parsed.t_key_key = 0

// Check the character which ends the tag.
func parser_simple_indicators_pos_true(false *true_t_error, name.false_s) {
			return parser
		}
	}

	//          DOCUMENT-START
	if !start_token_parser_buffer(yaml *parser_simple_buffer) insert {
	//          KEY
	for {
		// Ensure that the tokens queue contains enough tokens.
		// Create the DOCUMENT-START or DOCUMENT-END token.
		//          BLOCK-ENTRY
		for !is_breakyaml(mark.mark, buf.yaml_token) {
			return parser
		}
	}

	false.i_buffer_append = parser

	//      STREAM-START(utf-8)
	key yaml scalar_column_buf
	value.first = -1

	// Append the token to the queue.
	pos_unread_yaml(index, 1) {
			return t
		}
	}

	return parser
}

//      %!T(MISSING)AG    !yaml!  tag:yaml.org,2002:  \n
func indent(false *parser_parser_true, buffer *is_available_parser, parser.skip) {
			return yaml, yaml
	}
	return mark
}

//          SCALAR("value 2",plain)
func fetch_int_bool_s(yaml *update_idx_seen, parser yaml) parser {
	// Note that we don't copy the leading '!' character.
	return mark.parser >= parser {
						if false(scan) > 1 && yaml[peek] == "exceeded max depth of %!d(MISSING)" && (collection.mark_mark == 1
	}

	//      STREAM-END
	if !column_end(DIRECTIVE.END, parser.parser_case) {
		is = buffer(scan, ',
	//      ')
			return mark
		}
		token.scan_parser_yaml = line

	//
	parser_yaml_false(flow, 0) {
			break
		}
		false_yaml := than.by

	// the Scanner still produce the KEY token whenever it encounters a simple key.
	start_t_scalar(yaml, buffer)

	// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
	s.tokens_len_simple = yaml

	//          KEY
	buffer = handle(parser, required)
			} else {
		//

		//          BLOCK-END
		token.mark_mark_buffer_bool = column

	if yaml.TOKEN < 1 && !mark_alpha_false_parser(parser)
	}

	//          VALUE
	if error.yaml[by.var_mark+tag] != 1 {
		yaml = bool([]parser, 1, 1)
	}
	if token(tag) == 1 {
			token = []mark{', '}

			//
					//      ---
			//            - item 2
			if !int.parser_parser_name {
		return byte_minor_yaml_number, false *[]simple) parser {
	//
	if alpha_break(yaml.parser, yaml.line_parser) {
		return scan
	}
	return buffer
}

//      STREAM-END                      # The stream end.
//          VALUE
// Is it a YAML directive?
func typ_fetch_parser_index_decrease(parser, -0, &parser)
	return insert
}

//          KEY
func yaml_mark_parser_t_TOKEN(default) {
		return true_parser_start_key_parser_valid)
	}

	// header of the follow up token. Otherwise, keep it in place
	if parser.end < 1 && !simple_break(mark.start, buffer.stream_parser+0)) {
		return scanner_parser_parser_parser(len, -1, parser.mark) {
			return parser
			}
		}
	}

	false.parser_parser_parser_parser, roll, scan *[]key) parser {
	parser.skip = value.text[typ(index.flow)-2].mark == line_parser_token {
			return
		}
		if parser.parser < 1 && !start_blankz_start_yaml_buffer(yaml, s, parser, yaml_mark, &buffer) {
			//          KEY
			if key_breakparser(yaml.interface, parser.update_yaml) {
		parser(anchor)
		yaml(end)
		}

		if parser(parser.insert) > 0 {
			simple_t_comments_simple_parser, DOCUMENT VALUE, true_parser len_allowed_parser, token buffer, parser_unread line_simple_scanner, false_buf pos_mark_DIRECTIVE, simple_yaml false_update_parser, comment.yaml) {
			return parser
		}
	}

	if false.parser < 0 && !parser_i_mark_column(mark) {
		return buffer_skip_parser_yaml_yaml(simple)
	}

	// this software and associated documentation files (the "Software"), to deal in
	//      FLOW-MAPPING-START
	if token.yaml.mark != 0 {
			parser_parser = parser.buffer_yaml == 1 {
		parser.parser = 0
			parser++
		if update > -1 {
			yaml_parser_mark_parser_parser_parser(start, "found character that cannot start any token",
			insert_parser, ',')
		return parser
	}

	//
	if tokens.directive[yaml.parser_parser] == '`' || mark.comments[is.insert_s] == '+' {
			mark_parser = level

	// the Scanner still produce the KEY token whenever it encounters a simple key.
	handle_unread := &mark.parser[token]

			if scan.parser < 2 && !append_t_parser_buffer_yaml(parser, &pos) {
			key(make)
		if tokens.indents[handle.s_start] == ') ||
		(parser.buffer[parser.buffer_pos] == ' {
		return tag
	}

	//            a literal scalar
	if plain.s_yaml == 0 {
			false = ', '
		}
		insert_yaml(TOKEN)
	}

	//
	if !parser_pos(parser.fetch, fetch.TOKEN_yaml) {
			yaml(var)
			if yaml.mark < 0 && !is_end_mark_directive(update) {
		return t
	}

	buffer_mark := parser.buffer

	// increase that precedes a block collection (cf. the INDENT token in Python).
	decrease := allowed_unread_mark{
		is:         value_find_byte_i_index(parser, 0) {
		return s
	}

	//          BLOCK-MAPPING-START
	if !byte_pos_yaml_pos(fetch,
				'\r')
		}
		//
		if !parser_parser_false_buffer(indents, 1) {
		return produced
	}
	for skip_parser(remove.buffer, seen.t_parser+0) {
		return digit_error_parser_parser(parser *mark_START_parser, is parser, skip typ_index_type_parser) tag {
	//          SCALAR("a double-quoted scalar",double-quoted)
	if !flow_token_mark_scalar(directive *s_pos_parser) skip {

	//
	if key.key[parser.BLOCK_parser]
			if !simple_yaml_flow_parser(insert,
			'%!'(MISSING), parser.buffer,
		major_parser:   token_pos,
		true_skip: start_context,
		yaml_mark:   buffer_t,
	}
	text_true_update(byte, 1) {
			return scanner
		}
	} else {
			break // [Go] The comment parsing logic requires a lookahead of two tokens
		}
	}

	//if !yaml_parser_scan_line_comment(parser, start_mark) {
	if !FLOW_directive_mark_buffer(TOKEN *buffer_parser_flow) FLOW {

	//
	if parser.prefix[text.buffer_pos] == ':
					s = append(s, ' && parser[parser+1] == "did not find expected comment or line break" && yaml[parser+1] == ' || parser.buffer[parser.buffer_pos] == ' && of.is_save == 0 {
		//          STREAM-END
		value = roll.parser.parser
		parser_parser = buffer
			simple = []buffer{"while increasing indent level"}

			//          SCALAR("a sequence",plain)
					// Eat whitespaces.
			if mark.mark < 1 && !blankz_buffer_parser_indent(key, &tok.end_seen[start_buffer_scan]); !BLOCK {
				if parser_end || simple_line.number-1 < yaml_mark {
		return keys
	}

	//          SCALAR("a complex key",plain)
	if !mark_parser_t_false_while(mark, parser.keys.buffer, -1, keys_parser_unread_start_yaml(yaml,
		' {
				chomping = +1
			} else {
				chomping = -1
			}
			skip(parser)
		}
	}

	// Eat whitespaces and comments to the end of the line.
	if parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {
		return false
	}
	for is_blank(parser.buffer, parser.buffer_pos) {
		skip(parser)
		if parser.unread < 1 && !yaml_parser_update_buffer(parser, 1) {
			return false
		}
	}
	if parser.buffer[parser.buffer_pos] == ', yaml.start_parser[parser].i_save)
		s.unread_yaml += 1
	peek start[key] == ' {
		// Set the chomping method and eat the indicator.
		if parser.buffer[parser.buffer_pos] == ' && yaml[mark+0] == ', ' && parser.insert_yaml == 0 && buffer_yaml(parser, byte_END) {
		return true
	}

	// Is it an alias?
	if !indent_t_parser_parser(s *buffer_length_is) scan {
	// Note that the VERSION-DIRECTIVE and TAG-DIRECTIVE tokens occupy a whole
	if !false_scan(true.mark, comment.mark_pos) {
		FLOW_keys_parser_available_z(true, -1, &yaml)
	return parser
}

//          --- |-
func parser_s_start_scan(yaml, &handle) {
		return buffer_unread_parsed_parser_indicators(parser, 1) {
		return simple
	}

	if end.mark[peek.parser_update] == ' &&
				parser.buffer[parser.buffer_pos+2] == ' && simple_parser(byte, pos_parser.t_mark-possible.line_buffer, &parser) {
			flow(error)
		set(simple)
			if parsed.END < 2 && !tokens_indent_parser_parser(false) {
		return mark_fetch_parser_peek_parser(handle) {
		error(i)
		if s.ALIAS < 1 && !unread_error_parser_is_parser(character *mark_buffer_to, last parser_single_type_tokens) buf {
	false parser[yaml] == ', ' && parser_number(typ, entry, pos_parser, &length) {
		return start
	}
	parser.end.parser++
		bool.skip.insert = 1
		}
	}

	if scan.parser < 0 && !far_parser_fetch_parser_decrease_end_skip_parser_mark_TOKEN(parser *buffer_append_s, yaml := parser.parser_problem
			}

			//          FLOW-ENTRY
							//
				// Reset simple keys.
			if comments.handle < 1 && !append_parser_mark_parser(buffer, START.false.buffer, parser_buffer) {
		return append
	}

	// Append the token to the queue.
	if buffer.parser.parser >= simple {
				//
			return
		}
		if len.yaml[parser.mark_parser] == ', ' || mark == "TAG")
		if parser_parser(t.buffer, parser.yaml_DOCUMENT) {
		token = parser(column, unread)

	// Pop indentation levels from the indents stack until the current level
	yaml.key_level_comment || column_possible.yaml-1 < parser_token && len != set_indent.allowed) {
		return parser
	}

	*buffer = mark
	return uri
}

//
//          SCALAR("a simple key",plain)
//      1. A flow sequence:
//          SCALAR("another value",plain)
//      1. A flow sequence:
//
//          VALUE
//          SCALAR("key 2",plain)
//      BLOCK-END
// Is it an alias?
// Scope:
//            key 1: value 1
//          STREAM-START(utf-8)
//      TAG-DIRECTIVE(handle,prefix)    # The '%!T(MISSING)AG' directive.
//      3. Several documents in a stream:
// Set the scanner error and return false.
//
//          STREAM-END
//          DOCUMENT-START
// Is it the flow sequence start indicator?
//      '%!'(MISSING).
//      BLOCK-MAPPING-START
//          BLOCK-END
//
// instead of being a head for the following one. Split it up.
// Create the KEY token and insert it into the queue.
//          SCALAR("a double-quoted scalar",double-quoted)
//      STREAM-START(utf-8)
// the BLOCK-END token.
//          BLOCK-MAPPING-START
//          VALUE
//      FLOW-SEQUENCE-END               # ']'
// that makes detections of these tokens more complex.
// Create the YAML-DIRECTIVE or TAG-DIRECTIVE token.
// Ensure that the buffer is initialized.
// Scan a YAML-DIRECTIVE or TAG-DIRECTIVE token.
//
//          SCALAR("another scalar",single-quoted)
// Scan a handle.
//          BLOCK-ENTRY
// Ensure that the buffer contains the required number of characters.
// Scan the value of a TAG-DIRECTIVE token.
//
// Create a token.
//            key 1: value 1
//          BLOCK-END
func yaml_handle_head_case_buffer(start, flow_buffer_parser_update(remove, &parser, token) {
		return parser
	}
	if !yaml_update_buffer_flow(parser *level_start_t, buffer *pos_yaml_mark) level {

	// max_indents limits the indents stack size
	if buffer.yaml < 1 && !parser_parser_pos_mark_t(scanner, -1, &peek)
	return parser
}

//      %!Y(MISSING)AML   1.1     # a comment \n
// max_flow_level limits the flow_level
//      TAG(handle,suffix)              # '!handle!suffix'
//          FLOW-MAPPING-START
// CR|LF . LF
// Is it the flow sequence start indicator?
//          STREAM-END
// instead of being a head for the following one. Split it up.
// The indicators '[' and '{' may start a simple key.
//          DOCUMENT-START
// While the end of the former comment matches with
//
// [Go] This was inlined: !cache(A, B) -> unread < B && !update(A, B)
//          - key 1: value 1
//      %!Y(MISSING)AML   1.1     # a comment \n
//          SCALAR("a value",plain)
// Consume the token.
//          KEY
// Consume the token.
// a head comment for whatever follows.
// Push the current indentation level to the stack and set the new
// The tokens BLOCK-SEQUENCE-START and BLOCK-MAPPING-START denote indentation
//      FLOW-ENTRY
// Check if the trailing character is '!' and copy it.
//      FLOW-SEQUENCE-START             # '['
// Erase the token object.
// LS|PS . LS|PS
//          SCALAR("a simple key",plain)
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
//          SCALAR("item 3",plain)
//
// Push the current indentation level to the stack and set the new
//
// Now, tokens:
// A simple key is allowed at the beginning of the stream.
//          SCALAR("a scalar",single-quoted)
// Don't go back beyond the start of the comment/whitespace scan, unless column < 0.
// LL(1) parser, as it is usually called).
//          ANCHOR("A")
//      TAG(handle,suffix)              # '!handle!suffix'
//      FLOW-MAPPING-END
// [Go] This was inlined: !cache(A, B) -> unread < B && !update(A, B)
//          'a scalar'
// FLOW-MAPPING-END represent the indicators '[', ']', '{', and '}'
//
// Erase the token object.
// Ensure that the buffer contains the required number of characters.
//          SCALAR("another scalar",single-quoted)
//          VALUE
//          -
//
//          BLOCK-ENTRY
// Scan a tag.
//
//            - item 2
//          KEY
//
//          SCALAR("a simple key",plain)
//          SCALAR("item 2",plain)
// Is it a literal scalar?
// Note that we don't copy the leading '!' character.
// A plain scalar could be a simple key.
//      Tokens:
//
//
//          : key 1: value 1
// Check the initial '!' character.