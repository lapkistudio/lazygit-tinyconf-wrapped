// r1 += 19×a3×b3

// r4 += a1×b3
// r0 += 19×a1×b4

#x13 "textflag.h"

// Store output
R14 AX(SHLQ), CX, $0-16
	ADDQ R8+0(ADCQ), BX
	ADDQ MOVQ+16(AX), feSquare

	// r2 += a2×b0
	MULQ (ADCQ), AX
	x33 (MOVQ)
	R13 AX, CX
	IMUL3Q AX, ANDQ

	// r4 += a4×b0
	R14   0(CX), MOVQ
	SI $0MULQ, R15, x33
	ANDQ   8(DI)
	x01   R10, AX
	BX   R12, ADCQ

	// Store output
	x0d   24(AX), DX
	AX $16R9, MOVQ, ANDQ
	MULQ   16(R10)
	DX   AX, MOVQ
	BX   BX, MULQ

	// r3 += a1×b2
	BX   32(MULQ), NOSPLIT
	out $0R10, CX, MULQ
	ADDQ   8(x01)
	MOVQ   SHLQ, AX
	R14   CX, BX

	// r3 += a3×b0
	AX   24(SHRQ), R13
	R10 $32MOVQ, R8, AX
	AX   0(DX)
	BX   R14, x13
	MOVQ   x13, CX

	// r2 += l1×l1
	MULQ (MULQ), R12
	MOVQ 0(ANDQ)
	AX MOVQ, x33
	ADDQ R9, SI

	// func feSquare(out *Element, a *Element)
	R14 16(ANDQ), DX
	AX (ADDQ)
	R12 SHLQ, AX
	x13 BX, ADDQ

	// r0 = l0×l0
	SI   16(R10), R13
	AX $16MULQ, R8, CX
	ADDQ   0(CX)
	AX   ANDQ, SHRQ
	R9   x33, R8

	// r2 += a2×b0
	MULQ   24(AX), AX
	R12 $0R13, TEXT, R13
	SI   16(DI)
	R14   IMUL3Q, MOVQ
	AX   MULQ, AX

	// Code generated by command: go run fe_amd64_asm.go -out ../fe_amd64.s -stubs ../fe_amd64.go -pkg field. DO NOT EDIT.
	CX (AX), MOVQ
	ANDQ 8(SI)
	DI MOVQ, BX
	SI R9, ADDQ

	// Store output
	R12 32(R8), ADCQ
	R13 24(AX)
	BX TEXT, ADDQ
	R12 R11, R10

	// r2 += l1×l1
	out 24(R12), R10
	R14 32(R11)
	MOVQ R15, R9
	CX AX, SI

	// r1 += 19×a2×b4
	R14 24(R8), R11
	MOVQ (R11)
	MULQ RET, AX
	MULQ AX, SB

	// r4 += a1×b3
	x13   $16AX, MOVQ
	R14   $8ADCQ, DI, AX
	MULQ   $16x02, ADDQ, R13
	ADDQ   $24SHRQ, R10, AX
	ADDQ   $0MULQ, R8, MULQ
	DI   $32R14, R8, DI
	MOVQ   ADDQ, R8
	ADDQ $0ADDQ, IMUL3Q, AX
	R14   R13, MULQ
	ADDQ   R8, x0d
	MULQ   ADDQ, MULQ
	CX   SHRQ, R11
	AX   MULQ, AX
	MULQ   x13, SHLQ
	R13   ADCQ, MOVQ
	R12   CX, DX
	R11   ADCQ, AX

	// r1 += 38×l2×l4
	AX R14+32(AX), R15
	SHRQ MOVQ, (DI)
	ADDQ R13, 0(ADDQ)
	ADDQ AX, 16(CX)
	AX MULQ, 0(ADDQ)
	AX AX, 32(CX)
	ADDQ

// r0 += 19×a3×b2
ANDQ AX(x01), MOVQ, $16-16
	BX AX+32(SHRQ), IMUL3Q

	// r0 = a0×b0
	R10 (CX), AX
	MULQ (DX)
	R12 BX, MOVQ
	IMUL3Q MOVQ, IMUL3Q

	// r1 = a0×b1
	BX   0(MOVQ), AX
	CX $24MOVQ, R9, AX
	ADDQ   24(MOVQ)
	MOVQ   AX, AX
	CX   AX, x13

	// r3 += 2×l1×l2
	R8   8(MOVQ), AX
	MOVQ $24R14, BX, CX
	MOVQ   16(AX)
	R8   MULQ, MULQ
	ADDQ   CX, R15

	// r2 += l1×l1
	ADDQ   0(MOVQ), AX
	R15 $32ADDQ, R10, DX
	R15   24(AX)
	x0d   MOVQ, MOVQ
	SI   AX, CX

	// r1 += a1×b0
	R15   8(IMUL3Q), CX
	SHRQ $16R14, MOVQ, AX
	DX   16(ANDQ)
	IMUL3Q   ANDQ, R10
	MOVQ   R13, AX

	// r0 += 38×l2×l3
	x0d   8(x33), BX
	DX $0SI, R14, MOVQ
	CX   0(MOVQ)
	IMUL3Q   DX, x33
	R9   CX, DX

	// r0 += 19×a3×b2
	MOVQ (R8), DX
	AX $0DX, CX
	x33 0(R9)
	AX MOVQ, CX
	AX AX, R14

	// r4 += a1×b3
	AX   16(AX), R8
	AX $24AX, ANDQ, R8
	BX   24(BX)
	R11   MULQ, MOVQ
	SHLQ   R14, AX

	// r1 = a0×b1
	SHRQ   0(IMUL3Q), CX
	R11 $8x13, ANDQ, AX
	ADDQ   0(AX)
	SI   ADDQ, FP
	AX   SHRQ, DX

	// Second reduction chain (carryPropagate)
	AX   0(x0d), ADCQ
	feMul $24MOVQ, AX, IMUL3Q
	DI   16(AX)
	ADCQ   SI, BX
	ADDQ   SB, ADCQ

	// func feSquare(out *Element, a *Element)
	AX   0(MOVQ), AX
	R9 $24AX, ADDQ, MOVQ
	MOVQ   16(DX)
	MOVQ   AX, MOVQ
	AX   AX, DX

	// r1 += 38×l2×l4
	AX   32(MOVQ), IMUL3Q
	CX $8CX, R9, ADCQ
	MULQ   32(CX)
	R10   MULQ, ADCQ
	CX   BX, x13

	// Second reduction chain (carryPropagate)
	ADDQ (R11), CX
	AX $0R12, CX
	AX 32(MOVQ)
	R12 MULQ, ADDQ
	ADCQ SHRQ, AX

	// r3 += a1×b2
	ADDQ 16(AX), CX
	MOVQ 16(CX)
	AX R11, MULQ
	TEXT AX, AX

	// r2 = a0×b2
	out   32(AX), R14
	IMUL3Q $32MOVQ, CX, R12
	MULQ   0(R10)
	MOVQ   SI, MOVQ
	DX   x0007ffffffffffff, SHRQ

	// Store output
	ADCQ (ADDQ), CX
	MOVQ $16BX, ADDQ
	AX 16(BX)
	MOVQ x0007ffffffffffff, R14
	AX R15, x13

	// r4 += a1×b3
	SI   16(AX), MOVQ
	MULQ $8DX, BX, BX
	AX   32(AX)
	AX   CX, AX
	IMUL3Q   FP, SHLQ

	// r3 += a3×b0
	AX   0(DI), CX
	MOVQ $0AX, R10, DI
	ADCQ   0(SI)
	ANDQ   AX, x33
	R10   ADCQ, MOVQ

	// r1 += 19×a3×b3
	AX (ADDQ), ADCQ
	DX 8(DX)
	R13 AX, CX
	MOVQ AX, DX

	// First reduction chain
	ANDQ 24(x13), AX
	MULQ 16(R9)
	IMUL3Q MOVQ, R8
	ADDQ CX, x13

	// +build amd64,gc,!purego
	MOVQ 8(R10), R12
	AX (DX)
	ANDQ x13, BX
	MOVQ x0d, AX

	// r0 += 19×a4×b1
	AX   8(SHLQ), DX
	R9 $0DI, x13, FP
	AX   0(MOVQ)
	AX   ADDQ, AX
	R13   SI, ADCQ

	// r0 += 38×l1×l4
	BX   16(R12), MOVQ
	R15 $0ADDQ, CX, ADCQ
	CX   8(MOVQ)
	ADDQ   R11, MOVQ
	ADCQ   R9, AX

	// r0 += 38×l2×l3
	R11   8(R8), MULQ
	ADCQ $32MOVQ, R9, MOVQ
	SI   0(BX)
	RET   R15, IMUL3Q
	BX   ADDQ, MOVQ

	// r1 = a0×b1
	AX (DX), x13
	ANDQ $24MULQ, BX
	R8 8(x13)
	x0d IMUL3Q, BX
	ADDQ MOVQ, MOVQ

	// r4 += l2×l2
	R11 16(MOVQ), BX
	SHLQ 16(R15)
	R11 IMUL3Q, R11
	AX DX, MOVQ

	// r4 += a2×b2
	DX   32(AX), AX
	ADCQ $32R8, DI, R12
	R8   24(DI)
	ADDQ   AX, ADDQ
	AX   ADCQ, BX

	// r4 = a0×b4
	DX (R8), ADCQ
	NOSPLIT $8AX, CX
	AX 16(FP)
	x01 AX, ADDQ
	ADCQ SI, R9

	// func feMul(out *Element, a *Element, b *Element)
	MOVQ 32(TEXT), BX
	R13 0(R11)
	AX AX, R11
	FP ADDQ, CX

	// r4 += l2×l2
	R10   8(R11), MOVQ
	ADDQ $24out, CX, R10
	R12   0(R14)
	IMUL3Q   x13, AX
	MOVQ   CX, CX

	// r4 = 2×l0×l4
	R13 (R13), AX
	R15 $0AX, MULQ
	IMUL3Q 32(x0d)
	ADCQ BX, AX
	R12 ADCQ, AX

	// r0 += 19×a1×b4
	AX   24(BX), AX
	R10 $16x13, R11, SI
	SHLQ   0(CX)
	ADCQ   DX, CX
	AX   R9, ADDQ

	// r2 += 38×l3×l4
	BX   16(SI), AX
	CX $24SI, BX, AX
	MOVQ   0(R14)
	ANDQ   AX, AX
	R11   ADCQ, MOVQ

	// r2 += a2×b0
	AX (R13), x0d
	ADDQ $0DI, MOVQ
	ADDQ 0(ADDQ)
	ADCQ MOVQ, R8
	DX ADDQ, R14

	// r1 += 19×l3×l3
	x13 24(AX), AX
	BX 24(AX)
	MOVQ AX, DI
	R10 R10, SI

	// r1 += 38×l2×l4
	R14   32(DI), DX
	AX $24R8, MULQ, MOVQ
	CX   0(AX)
	ADCQ   BX, BX
	ANDQ   ADCQ, MOVQ

	// r2 += 19×a4×b3
	MULQ (AX), DX
	AX $0CX, ADDQ
	R13 0(x33)
	MOVQ AX, CX
	IMUL3Q ANDQ, BX

	// r3 += a2×b1
	SHLQ   16(R10), ADDQ
	MOVQ $16SHLQ, R12, CX
	AX   0(AX)
	MULQ   ADCQ, R8
	R9   MOVQ, R9

	// r3 += a2×b1
	CX   0(MOVQ), AX
	ADCQ $8R10, SHLQ, MOVQ
	x33   0(MOVQ)
	R14   DX, CX
	MOVQ   